{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加法器:\n",
    "# 本程式為建構一深度學習模型，將其訓練成一個加法器，輸入一段三位數 + 三位數之算式，計算及答案。 並比較不同神經元個數、Epoch次數之影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匯入所需library，主要使用keras建立神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8NdJXYdg6pI8",
    "outputId": "44e4c222-3028-4ff1-e7e9-92a9ed9cbc23"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自行生成加法算式資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rj_EA5nC7Ngu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "DIGITS = 3\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+ '\n",
    "\n",
    "# Generate Data\n",
    "questions = []\n",
    "expected = []\n",
    "print('Generating data...')\n",
    "for a in range(0, 999):\n",
    "    for b in range(0, 999):\n",
    "        q = '{}+{}'.format(str(a), str(b))    # 將 +號 插進兩數字中，產生數學式的字串\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a + b)\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        questions.append(query)\n",
    "        expected.append(ans)\n",
    "        \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzQoEPgI7QDu"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))      # char to integer\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))      # integer to char\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)\n",
    "      \n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將產生好的資料化為 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cF0wLfs8GHa0",
    "outputId": "b19a4a4b-39d6-47ad-d175-6aea0c89ae6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.int)  \n",
    "y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.int)\n",
    "\n",
    "# One-Hot encoding\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "    \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分訓練、驗證、測試資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "sIeS5P2eG1c5",
    "outputId": "614f18f3-cdde-4d07-ef77-94d9fe9c9f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(638720, 7, 12)\n",
      "(638720, 4, 12)\n",
      "Validation Data:\n",
      "(159680, 7, 12)\n",
      "(159680, 4, 12)\n",
      "Testing Data:\n",
      "(199601, 7, 12)\n",
      "(199601, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_ratio, random_state=0)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=test_ratio, random_state=0)\n",
    "\n",
    "print('Training Data:')\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lcKt0NOm7M6"
   },
   "outputs": [],
   "source": [
    "ctrain_x = train_x.reshape(train_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_x = test_x.reshape(test_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctrain_y = train_y.reshape(train_y.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_y = test_y.reshape(test_y.shape[0], -1, 1).squeeze(axis=2)\n",
    "cvalid_x = valid_x.reshape(valid_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "cvalid_y = valid_y.reshape(valid_y.shape[0], -1, 1).squeeze(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定訓練10個 epochs, 以不同的隱藏層神經元個數訓練，比較 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 24s 38us/step - loss: 10.5529 - acc: 0.4666 - val_loss: 9.5199 - val_acc: 0.3977\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 21s 33us/step - loss: 9.2665 - acc: 0.3688 - val_loss: 9.0893 - val_acc: 0.3512\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 24s 37us/step - loss: 9.0116 - acc: 0.3558 - val_loss: 8.9493 - val_acc: 0.3568\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 22s 34us/step - loss: 8.9206 - acc: 0.3538 - val_loss: 8.8824 - val_acc: 0.4031\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 21s 33us/step - loss: 8.8709 - acc: 0.3518 - val_loss: 8.8380 - val_acc: 0.3567\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 24s 38us/step - loss: 8.8323 - acc: 0.3508 - val_loss: 8.8061 - val_acc: 0.3362\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 22s 34us/step - loss: 8.8060 - acc: 0.3486 - val_loss: 8.7882 - val_acc: 0.3709\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 8.7811 - acc: 0.3479 - val_loss: 8.7617 - val_acc: 0.3618\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 8.7575 - acc: 0.3457 - val_loss: 8.7478 - val_acc: 0.3336\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 29s 46us/step - loss: 8.7413 - acc: 0.3449 - val_loss: 8.7261 - val_acc: 0.3427\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 9.5491 - acc: 0.3660 - val_loss: 8.5486 - val_acc: 0.3497\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 8.3159 - acc: 0.3281 - val_loss: 8.1103 - val_acc: 0.3062\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 30s 46us/step - loss: 8.0038 - acc: 0.3224 - val_loss: 7.8965 - val_acc: 0.3196\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 7.8380 - acc: 0.3153 - val_loss: 7.7766 - val_acc: 0.2823\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 7.7252 - acc: 0.3128 - val_loss: 7.6698 - val_acc: 0.2796\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 33s 52us/step - loss: 7.6449 - acc: 0.3099 - val_loss: 7.6052 - val_acc: 0.3044\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 7.5896 - acc: 0.3072 - val_loss: 7.5572 - val_acc: 0.2923\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 7.5425 - acc: 0.3057 - val_loss: 7.5188 - val_acc: 0.3450\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 7.5023 - acc: 0.3060 - val_loss: 7.4718 - val_acc: 0.2612\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 7.4684 - acc: 0.3038 - val_loss: 7.4537 - val_acc: 0.3638\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 9.0491 - acc: 0.3460 - val_loss: 8.0311 - val_acc: 0.3480\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 7.7647 - acc: 0.3132 - val_loss: 7.5683 - val_acc: 0.2865\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 7.4508 - acc: 0.3016 - val_loss: 7.3620 - val_acc: 0.2577\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 34s 52us/step - loss: 7.2971 - acc: 0.2928 - val_loss: 7.2363 - val_acc: 0.2889\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 7.1959 - acc: 0.2878 - val_loss: 7.1454 - val_acc: 0.2976\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 7.1182 - acc: 0.2835 - val_loss: 7.0887 - val_acc: 0.2895\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 40s 62us/step - loss: 7.0656 - acc: 0.2806 - val_loss: 7.0362 - val_acc: 0.2625\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 7.0230 - acc: 0.2789 - val_loss: 6.9920 - val_acc: 0.2804\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.9915 - acc: 0.2782 - val_loss: 6.9800 - val_acc: 0.2740\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.9668 - acc: 0.2759 - val_loss: 6.9525 - val_acc: 0.2738\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 37s 59us/step - loss: 8.7072 - acc: 0.3338 - val_loss: 7.6523 - val_acc: 0.3106\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 36s 57us/step - loss: 7.3755 - acc: 0.3031 - val_loss: 7.1829 - val_acc: 0.2330\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 36s 57us/step - loss: 7.0847 - acc: 0.2879 - val_loss: 7.0057 - val_acc: 0.3208\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.9356 - acc: 0.2788 - val_loss: 6.8802 - val_acc: 0.3038\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 37s 58us/step - loss: 6.8432 - acc: 0.2737 - val_loss: 6.8071 - val_acc: 0.2701\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.7766 - acc: 0.2703 - val_loss: 6.7522 - val_acc: 0.2635\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 36s 57us/step - loss: 6.7294 - acc: 0.2670 - val_loss: 6.7018 - val_acc: 0.2906\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.6968 - acc: 0.2649 - val_loss: 6.6829 - val_acc: 0.2729\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 37s 58us/step - loss: 6.6709 - acc: 0.2633 - val_loss: 6.6552 - val_acc: 0.2324\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.6477 - acc: 0.2621 - val_loss: 6.6293 - val_acc: 0.3152\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 39s 62us/step - loss: 8.5523 - acc: 0.3384 - val_loss: 7.4930 - val_acc: 0.2755\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 41s 64us/step - loss: 7.2406 - acc: 0.3049 - val_loss: 7.0523 - val_acc: 0.3099\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 42s 66us/step - loss: 6.9483 - acc: 0.2880 - val_loss: 6.8477 - val_acc: 0.2779\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.7941 - acc: 0.2767 - val_loss: 6.7285 - val_acc: 0.2736\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 41s 64us/step - loss: 6.7021 - acc: 0.2705 - val_loss: 6.6706 - val_acc: 0.2136\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 42s 66us/step - loss: 6.6452 - acc: 0.2648 - val_loss: 6.6309 - val_acc: 0.1955\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 38s 60us/step - loss: 6.6046 - acc: 0.2617 - val_loss: 6.5853 - val_acc: 0.2874\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 42s 65us/step - loss: 6.5727 - acc: 0.2606 - val_loss: 6.5638 - val_acc: 0.2152\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 51s 80us/step - loss: 6.5440 - acc: 0.2588 - val_loss: 6.5351 - val_acc: 0.2418\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 42s 66us/step - loss: 6.5167 - acc: 0.2581 - val_loss: 6.5013 - val_acc: 0.2432\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 8.3299 - acc: 0.3324 - val_loss: 7.2546 - val_acc: 0.3488\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 43s 68us/step - loss: 7.0170 - acc: 0.2930 - val_loss: 6.8473 - val_acc: 0.3388\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 52s 82us/step - loss: 6.7602 - acc: 0.2757 - val_loss: 6.6721 - val_acc: 0.2222\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.6316 - acc: 0.2663 - val_loss: 6.5823 - val_acc: 0.3210\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 56s 87us/step - loss: 6.5572 - acc: 0.2610 - val_loss: 6.5311 - val_acc: 0.2680\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 43s 68us/step - loss: 6.5064 - acc: 0.2576 - val_loss: 6.4856 - val_acc: 0.2377\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638720/638720 [==============================] - 42s 66us/step - loss: 6.4666 - acc: 0.2562 - val_loss: 6.4420 - val_acc: 0.2301\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 50s 78us/step - loss: 6.4330 - acc: 0.2534 - val_loss: 6.4134 - val_acc: 0.2114\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 42s 65us/step - loss: 6.4053 - acc: 0.2528 - val_loss: 6.3931 - val_acc: 0.2978\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 42s 66us/step - loss: 6.3831 - acc: 0.2512 - val_loss: 6.3628 - val_acc: 0.2733\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 50s 78us/step - loss: 8.2235 - acc: 0.3332 - val_loss: 7.1404 - val_acc: 0.3128\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 50s 79us/step - loss: 6.9042 - acc: 0.2905 - val_loss: 6.7247 - val_acc: 0.2934\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 50s 79us/step - loss: 6.6405 - acc: 0.2711 - val_loss: 6.5571 - val_acc: 0.2282\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.5187 - acc: 0.2613 - val_loss: 6.4966 - val_acc: 0.2167\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.4483 - acc: 0.2569 - val_loss: 6.4093 - val_acc: 0.2688\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.3993 - acc: 0.2535 - val_loss: 6.3712 - val_acc: 0.2628\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 47s 73us/step - loss: 6.3636 - acc: 0.2513 - val_loss: 6.3409 - val_acc: 0.2597\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.3355 - acc: 0.2500 - val_loss: 6.3262 - val_acc: 0.2311\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.3125 - acc: 0.2485 - val_loss: 6.3042 - val_acc: 0.2448\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.2953 - acc: 0.2473 - val_loss: 6.2789 - val_acc: 0.2784\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 50s 78us/step - loss: 8.0764 - acc: 0.3264 - val_loss: 7.0303 - val_acc: 0.3366\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 50s 79us/step - loss: 6.7941 - acc: 0.2838 - val_loss: 6.6319 - val_acc: 0.2825\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.5612 - acc: 0.2661 - val_loss: 6.4915 - val_acc: 0.2260\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 47s 74us/step - loss: 6.4578 - acc: 0.2582 - val_loss: 6.4202 - val_acc: 0.3011\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.3972 - acc: 0.2533 - val_loss: 6.3838 - val_acc: 0.2598\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 47s 73us/step - loss: 6.3553 - acc: 0.2499 - val_loss: 6.3537 - val_acc: 0.2854\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.3235 - acc: 0.2481 - val_loss: 6.3014 - val_acc: 0.2428\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.2969 - acc: 0.2454 - val_loss: 6.2788 - val_acc: 0.3021\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 48s 74us/step - loss: 6.2734 - acc: 0.2440 - val_loss: 6.2528 - val_acc: 0.2189\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 48s 75us/step - loss: 6.2523 - acc: 0.2428 - val_loss: 6.2424 - val_acc: 0.2301\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 52s 82us/step - loss: 7.9878 - acc: 0.3225 - val_loss: 6.9090 - val_acc: 0.2865\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 52s 81us/step - loss: 6.6883 - acc: 0.2772 - val_loss: 6.5437 - val_acc: 0.3012\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 51s 80us/step - loss: 6.4705 - acc: 0.2600 - val_loss: 6.4070 - val_acc: 0.3132\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 51s 81us/step - loss: 6.3694 - acc: 0.2525 - val_loss: 6.3338 - val_acc: 0.1792\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 53s 83us/step - loss: 6.3101 - acc: 0.2482 - val_loss: 6.2887 - val_acc: 0.2416\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 52s 82us/step - loss: 6.2686 - acc: 0.2459 - val_loss: 6.2422 - val_acc: 0.2673\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 53s 82us/step - loss: 6.2364 - acc: 0.2431 - val_loss: 6.2289 - val_acc: 0.1985\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 53s 84us/step - loss: 6.2091 - acc: 0.2409 - val_loss: 6.1960 - val_acc: 0.2565\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 52s 82us/step - loss: 6.1866 - acc: 0.2389 - val_loss: 6.1731 - val_acc: 0.2364\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 53s 83us/step - loss: 6.1681 - acc: 0.2377 - val_loss: 6.1661 - val_acc: 0.1676\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/10\n",
      "638720/638720 [==============================] - 57s 89us/step - loss: 7.8760 - acc: 0.3197 - val_loss: 6.7851 - val_acc: 0.3104\n",
      "Epoch 2/10\n",
      "638720/638720 [==============================] - 57s 89us/step - loss: 6.5784 - acc: 0.2697 - val_loss: 6.4502 - val_acc: 0.2199\n",
      "Epoch 3/10\n",
      "638720/638720 [==============================] - 60s 95us/step - loss: 6.3752 - acc: 0.2546 - val_loss: 6.3209 - val_acc: 0.2071\n",
      "Epoch 4/10\n",
      "638720/638720 [==============================] - 56s 88us/step - loss: 6.2846 - acc: 0.2480 - val_loss: 6.2475 - val_acc: 0.2691\n",
      "Epoch 5/10\n",
      "638720/638720 [==============================] - 57s 90us/step - loss: 6.2298 - acc: 0.2447 - val_loss: 6.1991 - val_acc: 0.2918\n",
      "Epoch 6/10\n",
      "638720/638720 [==============================] - 57s 89us/step - loss: 6.1915 - acc: 0.2423 - val_loss: 6.1821 - val_acc: 0.1621\n",
      "Epoch 7/10\n",
      "638720/638720 [==============================] - 58s 90us/step - loss: 6.1617 - acc: 0.2395 - val_loss: 6.1486 - val_acc: 0.2181\n",
      "Epoch 8/10\n",
      "638720/638720 [==============================] - 56s 88us/step - loss: 6.1380 - acc: 0.2379 - val_loss: 6.1350 - val_acc: 0.2617\n",
      "Epoch 9/10\n",
      "638720/638720 [==============================] - 58s 90us/step - loss: 6.1182 - acc: 0.2371 - val_loss: 6.1064 - val_acc: 0.2072\n",
      "Epoch 10/10\n",
      "638720/638720 [==============================] - 55s 87us/step - loss: 6.1014 - acc: 0.2356 - val_loss: 6.1009 - val_acc: 0.2454\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for n_neurons in range(50, 501, 50):\n",
    "    input1 = Input(shape=(84,))\n",
    "    w1 = Dense(n_neurons, activation='relu', name='weight1')\n",
    "    dense1 = w1(input1)\n",
    "    w2 = Dense(48, activation='softmax', name='weight2')\n",
    "    output1 = w2(dense1)\n",
    "\n",
    "    model = Model(inputs=[input1], outputs=[output1])\n",
    "    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model.fit(x=[ctrain_x], y=[ctrain_y], validation_data=[cvalid_x, cvalid_y], epochs=10)\n",
    "    \n",
    "    # 預測測試集\n",
    "    predicted = model.predict(ctest_x).reshape(ctest_x.shape[0], 4, 12)\n",
    "    \n",
    "    # 將預測結果(one-hot編碼)轉回一般數值\n",
    "    labels = []\n",
    "    ans = []\n",
    "    for i in range(0, len(test_y)):\n",
    "        labels.append(ctable.decode(test_y[i]))\n",
    "        ans.append(ctable.decode(predicted[i]))\n",
    "    # 計算測試資料正確率\n",
    "    acc = accuracy_score(ans, labels)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下圖可發現，隨著神經元個數變多，accuracy持續成長，並逐漸緩慢下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "plt.rcParams['font.sans-serif']=['SimHei']   # 設定中文字體\n",
    "plt.title(u'不同神經元數對accuracy之影響(固定訓練10個epoch)')\n",
    "plt.xlabel('number of neurons')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.plot(np.arange(50, 501, 50), acc_list, label='test_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定神經元個數為300，比較訓練不同 epoch 次數之影響，並畫出訓練過程loss與accuracy之變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3488
    },
    "colab_type": "code",
    "id": "-ByAB5sNlvGf",
    "outputId": "89da3c66-65ae-4400-b4f8-da19f31fd57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 8.3897 - val_loss: 7.3085\n",
      "accuracy:  0.6156625751503007\n",
      "Epoch 2/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 7.0512 - val_loss: 6.8765\n",
      "accuracy:  0.7414015531062125\n",
      "Epoch 3/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 33s 52us/step - loss: 6.7867 - val_loss: 6.7056\n",
      "accuracy:  0.7803669839679359\n",
      "Epoch 4/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.6599 - val_loss: 6.6040\n",
      "accuracy:  0.807314629258517\n",
      "Epoch 5/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.5824 - val_loss: 6.5455\n",
      "accuracy:  0.8209794589178356\n",
      "Epoch 6/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.5292 - val_loss: 6.5055\n",
      "accuracy:  0.8281938877755511\n",
      "Epoch 7/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.4885 - val_loss: 6.4705\n",
      "accuracy:  0.8377943386773548\n",
      "Epoch 8/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.4577 - val_loss: 6.4392\n",
      "accuracy:  0.8458479458917836\n",
      "Epoch 9/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.4326 - val_loss: 6.4140\n",
      "accuracy:  0.8503444388777555\n",
      "Epoch 10/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.4131 - val_loss: 6.4054\n",
      "accuracy:  0.8535884268537074\n",
      "Epoch 11/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.3947 - val_loss: 6.3858\n",
      "accuracy:  0.8639842184368738\n",
      "Epoch 12/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.3781 - val_loss: 6.3661\n",
      "accuracy:  0.8673409318637274\n",
      "Epoch 13/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.3634 - val_loss: 6.3551\n",
      "accuracy:  0.8663827655310621\n",
      "Epoch 14/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.3486 - val_loss: 6.3499\n",
      "accuracy:  0.8700964428857716\n",
      "Epoch 15/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.3368 - val_loss: 6.3248\n",
      "accuracy:  0.877122995991984\n",
      "Epoch 16/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 49us/step - loss: 6.3248 - val_loss: 6.3217\n",
      "accuracy:  0.8772732965931864\n",
      "Epoch 17/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.3140 - val_loss: 6.2976\n",
      "accuracy:  0.8862850701402806\n",
      "Epoch 18/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.3040 - val_loss: 6.2900\n",
      "accuracy:  0.8860283066132264\n",
      "Epoch 19/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.2946 - val_loss: 6.2900\n",
      "accuracy:  0.8878694889779559\n",
      "Epoch 20/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2870 - val_loss: 6.2804\n",
      "accuracy:  0.8880761523046092\n",
      "Epoch 21/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2808 - val_loss: 6.2728\n",
      "accuracy:  0.8901114729458918\n",
      "Epoch 22/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2750 - val_loss: 6.2708\n",
      "accuracy:  0.892566382765531\n",
      "Epoch 23/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2692 - val_loss: 6.2711\n",
      "accuracy:  0.8932552605210421\n",
      "Epoch 24/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.2646 - val_loss: 6.2632\n",
      "accuracy:  0.8947081663326654\n",
      "Epoch 25/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.2597 - val_loss: 6.2682\n",
      "accuracy:  0.8950275551102205\n",
      "Epoch 26/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.2555 - val_loss: 6.2513\n",
      "accuracy:  0.8983404308617234\n",
      "Epoch 27/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.2512 - val_loss: 6.2542\n",
      "accuracy:  0.8982778056112224\n",
      "Epoch 28/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2475 - val_loss: 6.2421\n",
      "accuracy:  0.8992735470941884\n",
      "Epoch 29/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2441 - val_loss: 6.2322\n",
      "accuracy:  0.8981212424849699\n",
      "Epoch 30/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 33s 51us/step - loss: 6.2403 - val_loss: 6.2383\n",
      "accuracy:  0.8991670841683367\n",
      "Epoch 31/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2360 - val_loss: 6.2329\n",
      "accuracy:  0.9026490480961924\n",
      "Epoch 32/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.2323 - val_loss: 6.2243\n",
      "accuracy:  0.9051102204408817\n",
      "Epoch 33/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2276 - val_loss: 6.2224\n",
      "accuracy:  0.9059619238476954\n",
      "Epoch 34/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.2239 - val_loss: 6.2374\n",
      "accuracy:  0.9040831663326653\n",
      "Epoch 35/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2200 - val_loss: 6.2160\n",
      "accuracy:  0.907439879759519\n",
      "Epoch 36/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2171 - val_loss: 6.2029\n",
      "accuracy:  0.9089115731462926\n",
      "Epoch 37/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2137 - val_loss: 6.2070\n",
      "accuracy:  0.9084731963927856\n",
      "Epoch 38/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.2105 - val_loss: 6.2083\n",
      "accuracy:  0.9092810621242485\n",
      "Epoch 39/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2078 - val_loss: 6.2098\n",
      "accuracy:  0.9084105711422845\n",
      "Epoch 40/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.2052 - val_loss: 6.2011\n",
      "accuracy:  0.9109218436873747\n",
      "Epoch 41/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.2022 - val_loss: 6.1963\n",
      "accuracy:  0.9119175851703407\n",
      "Epoch 42/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1994 - val_loss: 6.1984\n",
      "accuracy:  0.9122870741482966\n",
      "Epoch 43/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1972 - val_loss: 6.1962\n",
      "accuracy:  0.9120741482965932\n",
      "Epoch 44/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.1942 - val_loss: 6.1829\n",
      "accuracy:  0.9106650801603207\n",
      "Epoch 45/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1923 - val_loss: 6.1835\n",
      "accuracy:  0.9160571142284569\n",
      "Epoch 46/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1897 - val_loss: 6.1820\n",
      "accuracy:  0.9148922845691383\n",
      "Epoch 47/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1868 - val_loss: 6.1817\n",
      "accuracy:  0.9163451903807616\n",
      "Epoch 48/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1842 - val_loss: 6.1806\n",
      "accuracy:  0.9144726953907816\n",
      "Epoch 49/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1806 - val_loss: 6.1837\n",
      "accuracy:  0.9164892284569138\n",
      "Epoch 50/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1783 - val_loss: 6.1799\n",
      "accuracy:  0.9164391282565131\n",
      "Epoch 51/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1759 - val_loss: 6.1762\n",
      "accuracy:  0.9190944388777555\n",
      "Epoch 52/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1739 - val_loss: 6.1693\n",
      "accuracy:  0.9189190881763527\n",
      "Epoch 53/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1715 - val_loss: 6.1625\n",
      "accuracy:  0.9195390781563126\n",
      "Epoch 54/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 48us/step - loss: 6.1696 - val_loss: 6.1716\n",
      "accuracy:  0.9203657314629259\n",
      "Epoch 55/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1679 - val_loss: 6.1690\n",
      "accuracy:  0.9197269539078157\n",
      "Epoch 56/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1666 - val_loss: 6.1597\n",
      "accuracy:  0.9215994488977955\n",
      "Epoch 57/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1647 - val_loss: 6.1571\n",
      "accuracy:  0.9237224448897795\n",
      "Epoch 58/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1627 - val_loss: 6.1571\n",
      "accuracy:  0.9225137775551102\n",
      "Epoch 59/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1618 - val_loss: 6.1599\n",
      "accuracy:  0.9228206412825651\n",
      "Epoch 60/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1602 - val_loss: 6.1556\n",
      "accuracy:  0.922376002004008\n",
      "Epoch 61/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.1585 - val_loss: 6.1561\n",
      "accuracy:  0.9248559619238477\n",
      "Epoch 62/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1574 - val_loss: 6.1558\n",
      "accuracy:  0.921937625250501\n",
      "Epoch 63/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1560 - val_loss: 6.1602\n",
      "accuracy:  0.9241482965931864\n",
      "Epoch 64/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1548 - val_loss: 6.1654\n",
      "accuracy:  0.9238602204408818\n",
      "Epoch 65/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1533 - val_loss: 6.1643\n",
      "accuracy:  0.9227392284569138\n",
      "Epoch 66/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1512 - val_loss: 6.1533\n",
      "accuracy:  0.9233341683366734\n",
      "Epoch 67/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.1498 - val_loss: 6.1634\n",
      "accuracy:  0.9211548096192385\n",
      "Epoch 68/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1486 - val_loss: 6.1554\n",
      "accuracy:  0.9232339679358718\n",
      "Epoch 69/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 48us/step - loss: 6.1473 - val_loss: 6.1445\n",
      "accuracy:  0.9255886773547094\n",
      "Epoch 70/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1457 - val_loss: 6.1451\n",
      "accuracy:  0.9248496993987976\n",
      "Epoch 71/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 31s 49us/step - loss: 6.1449 - val_loss: 6.1478\n",
      "accuracy:  0.9246555611222445\n",
      "Epoch 72/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1432 - val_loss: 6.1357\n",
      "accuracy:  0.9279934869739479\n",
      "Epoch 73/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 30s 47us/step - loss: 6.1418 - val_loss: 6.1487\n",
      "accuracy:  0.9245804108216433\n",
      "Epoch 74/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.1408 - val_loss: 6.1349\n",
      "accuracy:  0.929314879759519\n",
      "Epoch 75/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 37s 57us/step - loss: 6.1389 - val_loss: 6.1402\n",
      "accuracy:  0.9262900801603207\n",
      "Epoch 76/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1380 - val_loss: 6.1573\n",
      "accuracy:  0.9259143286573146\n",
      "Epoch 77/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1372 - val_loss: 6.1412\n",
      "accuracy:  0.9295215430861723\n",
      "Epoch 78/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1360 - val_loss: 6.1310\n",
      "accuracy:  0.9292146793587175\n",
      "Epoch 79/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1349 - val_loss: 6.1416\n",
      "accuracy:  0.9259456412825652\n",
      "Epoch 80/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1336 - val_loss: 6.1369\n",
      "accuracy:  0.9280811623246493\n",
      "Epoch 81/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1322 - val_loss: 6.1449\n",
      "accuracy:  0.9282377254509018\n",
      "Epoch 82/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1317 - val_loss: 6.1394\n",
      "accuracy:  0.9294651803607215\n",
      "Epoch 83/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1305 - val_loss: 6.1320\n",
      "accuracy:  0.9285508517034068\n",
      "Epoch 84/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1292 - val_loss: 6.1277\n",
      "accuracy:  0.9298221442885771\n",
      "Epoch 85/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1279 - val_loss: 6.1225\n",
      "accuracy:  0.9320140280561122\n",
      "Epoch 86/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1275 - val_loss: 6.1246\n",
      "accuracy:  0.9305110220440882\n",
      "Epoch 87/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1262 - val_loss: 6.1348\n",
      "accuracy:  0.9277993486973948\n",
      "Epoch 88/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1253 - val_loss: 6.1266\n",
      "accuracy:  0.932314629258517\n",
      "Epoch 89/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.1243 - val_loss: 6.1299\n",
      "accuracy:  0.9300726452905812\n",
      "Epoch 90/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.1235 - val_loss: 6.1209\n",
      "accuracy:  0.9333855210420842\n",
      "Epoch 91/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1225 - val_loss: 6.1261\n",
      "accuracy:  0.9307740480961924\n",
      "Epoch 92/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1218 - val_loss: 6.1182\n",
      "accuracy:  0.9326340180360722\n",
      "Epoch 93/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1203 - val_loss: 6.1182\n",
      "accuracy:  0.9322707915831663\n",
      "Epoch 94/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1198 - val_loss: 6.1167\n",
      "accuracy:  0.9315944388777555\n",
      "Epoch 95/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1191 - val_loss: 6.1135\n",
      "accuracy:  0.9326590681362725\n",
      "Epoch 96/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1180 - val_loss: 6.1212\n",
      "accuracy:  0.9328657314629258\n",
      "Epoch 97/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1173 - val_loss: 6.1187\n",
      "accuracy:  0.9338301603206413\n",
      "Epoch 98/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.1162 - val_loss: 6.1122\n",
      "accuracy:  0.9331788577154309\n",
      "Epoch 99/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1158 - val_loss: 6.1100\n",
      "accuracy:  0.9343061122244489\n",
      "Epoch 100/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1148 - val_loss: 6.1239\n",
      "accuracy:  0.9319889779559118\n",
      "Epoch 101/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1146 - val_loss: 6.1079\n",
      "accuracy:  0.9339804609218437\n",
      "Epoch 102/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1136 - val_loss: 6.1076\n",
      "accuracy:  0.9337925851703407\n",
      "Epoch 103/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.1129 - val_loss: 6.1181\n",
      "accuracy:  0.9314942384769539\n",
      "Epoch 104/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1126 - val_loss: 6.1228\n",
      "accuracy:  0.9320516032064128\n",
      "Epoch 105/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1117 - val_loss: 6.1039\n",
      "accuracy:  0.9345941883767535\n",
      "Epoch 106/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 53us/step - loss: 6.1110 - val_loss: 6.1133\n",
      "accuracy:  0.9326277555110221\n",
      "Epoch 107/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1101 - val_loss: 6.1139\n",
      "accuracy:  0.9336548096192385\n",
      "Epoch 108/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1093 - val_loss: 6.1002\n",
      "accuracy:  0.935871743486974\n",
      "Epoch 109/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 34s 54us/step - loss: 6.1084 - val_loss: 6.0996\n",
      "accuracy:  0.9355085170340681\n",
      "Epoch 110/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 36s 56us/step - loss: 6.1074 - val_loss: 6.1004\n",
      "accuracy:  0.9352267034068136\n",
      "Epoch 111/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 55us/step - loss: 6.1073 - val_loss: 6.1179\n",
      "accuracy:  0.9315944388777555\n",
      "Epoch 112/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 35s 54us/step - loss: 6.1069 - val_loss: 6.1134\n",
      "accuracy:  0.9338865230460922\n",
      "Epoch 113/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 29s 46us/step - loss: 6.1055 - val_loss: 6.0986\n",
      "accuracy:  0.9361786072144288\n",
      "Epoch 114/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1048 - val_loss: 6.1067\n",
      "accuracy:  0.9353456913827656\n",
      "Epoch 115/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1048 - val_loss: 6.1006\n",
      "accuracy:  0.9355210420841683\n",
      "Epoch 116/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1045 - val_loss: 6.0951\n",
      "accuracy:  0.9371367735470942\n",
      "Epoch 117/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 43us/step - loss: 6.1034 - val_loss: 6.1046\n",
      "accuracy:  0.934249749498998\n",
      "Epoch 118/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1024 - val_loss: 6.1047\n",
      "accuracy:  0.9341119739478958\n",
      "Epoch 119/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1017 - val_loss: 6.0884\n",
      "accuracy:  0.9371555611222445\n",
      "Epoch 120/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1012 - val_loss: 6.0995\n",
      "accuracy:  0.9387900801603206\n",
      "Epoch 121/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.1005 - val_loss: 6.1150\n",
      "accuracy:  0.9372244488977955\n",
      "Epoch 122/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0999 - val_loss: 6.0959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9374686873747495\n",
      "Epoch 123/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0992 - val_loss: 6.0946\n",
      "accuracy:  0.9377066633266533\n",
      "Epoch 124/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0983 - val_loss: 6.1227\n",
      "accuracy:  0.9369050601202404\n",
      "Epoch 125/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0986 - val_loss: 6.0955\n",
      "accuracy:  0.9368800100200401\n",
      "Epoch 126/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0974 - val_loss: 6.1063\n",
      "accuracy:  0.9368987975951903\n",
      "Epoch 127/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0973 - val_loss: 6.0961\n",
      "accuracy:  0.9382452404809619\n",
      "Epoch 128/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0958 - val_loss: 6.1014\n",
      "accuracy:  0.9376690881763527\n",
      "Epoch 129/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0959 - val_loss: 6.0899\n",
      "accuracy:  0.9377567635270541\n",
      "Epoch 130/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0952 - val_loss: 6.0959\n",
      "accuracy:  0.9361535571142284\n",
      "Epoch 131/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0944 - val_loss: 6.0867\n",
      "accuracy:  0.9390969438877755\n",
      "Epoch 132/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0938 - val_loss: 6.0941\n",
      "accuracy:  0.9369676853707415\n",
      "Epoch 133/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0929 - val_loss: 6.0900\n",
      "accuracy:  0.9377567635270541\n",
      "Epoch 134/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0919 - val_loss: 6.0999\n",
      "accuracy:  0.936560621242485\n",
      "Epoch 135/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0914 - val_loss: 6.0844\n",
      "accuracy:  0.9391470440881764\n",
      "Epoch 136/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0908 - val_loss: 6.0854\n",
      "accuracy:  0.937813126252505\n",
      "Epoch 137/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0904 - val_loss: 6.0905\n",
      "accuracy:  0.9394163326653306\n",
      "Epoch 138/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0898 - val_loss: 6.0843\n",
      "accuracy:  0.9381513026052104\n",
      "Epoch 139/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0889 - val_loss: 6.0821\n",
      "accuracy:  0.9382640280561122\n",
      "Epoch 140/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0882 - val_loss: 6.0912\n",
      "accuracy:  0.9377567635270541\n",
      "Epoch 141/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0872 - val_loss: 6.1020\n",
      "accuracy:  0.9357965931863728\n",
      "Epoch 142/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0874 - val_loss: 6.0813\n",
      "accuracy:  0.9405811623246493\n",
      "Epoch 143/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0867 - val_loss: 6.0899\n",
      "accuracy:  0.9378256513026052\n",
      "Epoch 144/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0858 - val_loss: 6.0848\n",
      "accuracy:  0.938934118236473\n",
      "Epoch 145/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0854 - val_loss: 6.0830\n",
      "accuracy:  0.9403181362725451\n",
      "Epoch 146/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0848 - val_loss: 6.0907\n",
      "accuracy:  0.9380511022044088\n",
      "Epoch 147/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0844 - val_loss: 6.0864\n",
      "accuracy:  0.9405748997995992\n",
      "Epoch 148/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0837 - val_loss: 6.0837\n",
      "accuracy:  0.9381325150300601\n",
      "Epoch 149/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0834 - val_loss: 6.0722\n",
      "accuracy:  0.9394225951903807\n",
      "Epoch 150/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0823 - val_loss: 6.0912\n",
      "accuracy:  0.9379696893787575\n",
      "Epoch 151/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0819 - val_loss: 6.0852\n",
      "accuracy:  0.93812625250501\n",
      "Epoch 152/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0819 - val_loss: 6.0831\n",
      "accuracy:  0.9408942885771543\n",
      "Epoch 153/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0813 - val_loss: 6.0782\n",
      "accuracy:  0.93937249498998\n",
      "Epoch 154/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0809 - val_loss: 6.0866\n",
      "accuracy:  0.9385395791583167\n",
      "Epoch 155/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0805 - val_loss: 6.0850\n",
      "accuracy:  0.9366169839679359\n",
      "Epoch 156/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0806 - val_loss: 6.0741\n",
      "accuracy:  0.9424536573146293\n",
      "Epoch 157/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0796 - val_loss: 6.0791\n",
      "accuracy:  0.9403494488977956\n",
      "Epoch 158/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0796 - val_loss: 6.0845\n",
      "accuracy:  0.9384581663326653\n",
      "Epoch 159/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0784 - val_loss: 6.0873\n",
      "accuracy:  0.9397983466933868\n",
      "Epoch 160/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0784 - val_loss: 6.0830\n",
      "accuracy:  0.9394664328657315\n",
      "Epoch 161/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0780 - val_loss: 6.0778\n",
      "accuracy:  0.9378444388777555\n",
      "Epoch 162/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 41us/step - loss: 6.0771 - val_loss: 6.0840\n",
      "accuracy:  0.9397419839679358\n",
      "Epoch 163/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0774 - val_loss: 6.0914\n",
      "accuracy:  0.9395102705410822\n",
      "Epoch 164/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0767 - val_loss: 6.0772\n",
      "accuracy:  0.9392785571142285\n",
      "Epoch 165/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0762 - val_loss: 6.0753\n",
      "accuracy:  0.9408003507014028\n",
      "Epoch 166/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0758 - val_loss: 6.0730\n",
      "accuracy:  0.9404684368737475\n",
      "Epoch 167/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0751 - val_loss: 6.0692\n",
      "accuracy:  0.9410383266533067\n",
      "Epoch 168/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0747 - val_loss: 6.0668\n",
      "accuracy:  0.941000751503006\n",
      "Epoch 169/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0745 - val_loss: 6.0853\n",
      "accuracy:  0.940249248496994\n",
      "Epoch 170/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 43us/step - loss: 6.0744 - val_loss: 6.0787\n",
      "accuracy:  0.9395666332665331\n",
      "Epoch 171/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 24s 38us/step - loss: 6.0736 - val_loss: 6.0717\n",
      "accuracy:  0.9417710420841683\n",
      "Epoch 172/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 40us/step - loss: 6.0733 - val_loss: 6.0667\n",
      "accuracy:  0.9423158817635271\n",
      "Epoch 173/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0729 - val_loss: 6.0672\n",
      "accuracy:  0.942685370741483\n",
      "Epoch 174/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 41us/step - loss: 6.0725 - val_loss: 6.0762\n",
      "accuracy:  0.9393349198396793\n",
      "Epoch 175/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 27s 42us/step - loss: 6.0718 - val_loss: 6.0783\n",
      "accuracy:  0.9394539078156313\n",
      "Epoch 176/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 32s 50us/step - loss: 6.0720 - val_loss: 6.0798\n",
      "accuracy:  0.9391032064128256\n",
      "Epoch 177/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 26s 40us/step - loss: 6.0718 - val_loss: 6.0746\n",
      "accuracy:  0.9414453907815631\n",
      "Epoch 178/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 37us/step - loss: 6.0714 - val_loss: 6.0745\n",
      "accuracy:  0.9406500501002004\n",
      "Epoch 179/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0710 - val_loss: 6.0755\n",
      "accuracy:  0.9408379258517034\n",
      "Epoch 180/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0709 - val_loss: 6.0725\n",
      "accuracy:  0.9413076152304609\n",
      "Epoch 181/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 24s 37us/step - loss: 6.0710 - val_loss: 6.0698\n",
      "accuracy:  0.941940130260521\n",
      "Epoch 182/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0706 - val_loss: 6.0685\n",
      "accuracy:  0.9429170841683366\n",
      "Epoch 183/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0699 - val_loss: 6.0645\n",
      "accuracy:  0.9392597695390782\n",
      "Epoch 184/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0696 - val_loss: 6.0604\n",
      "accuracy:  0.9424160821643287\n",
      "Epoch 185/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 37us/step - loss: 6.0689 - val_loss: 6.0815\n",
      "accuracy:  0.9429296092184368\n",
      "Epoch 186/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0689 - val_loss: 6.0708\n",
      "accuracy:  0.9407690380761523\n",
      "Epoch 187/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0686 - val_loss: 6.0680\n",
      "accuracy:  0.9409882264529058\n",
      "Epoch 188/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0685 - val_loss: 6.0777\n",
      "accuracy:  0.9409443887775552\n",
      "Epoch 189/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0674 - val_loss: 6.0756\n",
      "accuracy:  0.9414203406813627\n",
      "Epoch 190/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0673 - val_loss: 6.0762\n",
      "accuracy:  0.9412512525050101\n",
      "Epoch 191/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0667 - val_loss: 6.0656\n",
      "accuracy:  0.9421843687374749\n",
      "Epoch 192/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 22s 35us/step - loss: 6.0664 - val_loss: 6.0618\n",
      "accuracy:  0.9435370741482966\n",
      "Epoch 193/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 24s 37us/step - loss: 6.0664 - val_loss: 6.0659\n",
      "accuracy:  0.9416144789579158\n",
      "Epoch 194/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0656 - val_loss: 6.0645\n",
      "accuracy:  0.9419589178356713\n",
      "Epoch 195/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0654 - val_loss: 6.0663\n",
      "accuracy:  0.9396543086172344\n",
      "Epoch 196/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 35us/step - loss: 6.0644 - val_loss: 6.0613\n",
      "accuracy:  0.9442760521042084\n",
      "Epoch 197/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0641 - val_loss: 6.0650\n",
      "accuracy:  0.942622745490982\n",
      "Epoch 198/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0635 - val_loss: 6.0722\n",
      "accuracy:  0.9427229458917835\n",
      "Epoch 199/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0636 - val_loss: 6.0610\n",
      "accuracy:  0.9414704408817636\n",
      "Epoch 200/200\n",
      "Train on 638720 samples, validate on 159680 samples\n",
      "Epoch 1/1\n",
      "638720/638720 [==============================] - 23s 36us/step - loss: 6.0623 - val_loss: 6.0683\n",
      "accuracy:  0.9439190881763527\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 200\n",
    "input1 = Input(shape=(84,))\n",
    "w1 = Dense(300, activation='relu', name='weight1')\n",
    "dense1 = w1(input1)\n",
    "w2 = Dense(48, activation='softmax', name='weight2')\n",
    "output1 = w2(dense1)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output1])\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy'])\n",
    "\n",
    "accuracy_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for i in range(1, epoch_size+1):\n",
    "    print('Epoch {}/{}'.format(i, epoch_size))\n",
    "    h = model.fit(x=[ctrain_x], y=[ctrain_y], validation_data=[cvalid_x, cvalid_y])\n",
    "    train_loss_list.append(h.history['loss'][0])\n",
    "    val_loss_list.append(h.history['val_loss'][0])\n",
    "    \n",
    "    # 預測驗證集\n",
    "    predicted = model.predict(cvalid_x).reshape(cvalid_x.shape[0], 4, 12)\n",
    "    # 將預測結果(one-hot編碼)轉回一般數值\n",
    "    labels = []\n",
    "    ans = []\n",
    "    for i in range(0, len(valid_y)):\n",
    "      labels.append(ctable.decode(valid_y[i]))\n",
    "      ans.append(ctable.decode(predicted[i]))\n",
    "\n",
    "    # 計算正確率\n",
    "    acc = accuracy_score(ans, labels)\n",
    "    print('accuracy: ', acc)\n",
    "    accuracy_list.append(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下方兩張圖:\n",
    "## 第一張是隨著training epoch變多，訓練誤差和驗證誤差均持續降低。\n",
    "## 第二張圖則是隨著training epoch變多，驗證accuracy持續上升至收斂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 隨著 epoch 次數不同，loss 之變化\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(1, epoch_size+1, 1), train_loss_list, label='train_loss')\n",
    "plt.plot(range(1, epoch_size+1, 1), val_loss_list, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 隨著 epoch 次數不同，accuracy 之變化\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(accuracy_list, label='valid_accuracy' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用測試集評估最終結果，accuracy 0.9414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9414732391120285\n"
     ]
    }
   ],
   "source": [
    "# 預測測試集\n",
    "predicted = model.predict(ctest_x).reshape(ctest_x.shape[0], 4, 12)\n",
    "# 將預測結果(one-hot編碼)轉回一般數值\n",
    "labels = []\n",
    "ans = []\n",
    "for i in range(0, len(ctest_y)):\n",
    "  labels.append(ctable.decode(test_y[i]))\n",
    "  ans.append(ctable.decode(predicted[i]))\n",
    "\n",
    "# 計算正確率\n",
    "acc = accuracy_score(ans, labels)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "myAdder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
