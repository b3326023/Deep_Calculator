{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2277,
     "status": "ok",
     "timestamp": 1555767645942,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "8NdJXYdg6pI8",
    "outputId": "6f1dbf21-2e8e-4767-9f8f-baea099c4aaa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-095a32613292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rj_EA5nC7Ngu"
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 100000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+ '\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' ' * len(str(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1555767662949,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "CSkrRpGx-nnW",
    "outputId": "d797b8c3-07b9-48df-dbb3-9821cbc12811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "\n",
    "print('Generating data...')\n",
    "\n",
    "for a in range(0, 999):\n",
    "    for b in range(0, 999):\n",
    "        q = '{}+{}'.format(str(a), str(b))    # 將 +號 插進兩數字中，產生數學式的字串\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a + b)\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        questions.append(query)\n",
    "        expected.append(ans)\n",
    "        \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzQoEPgI7QDu"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))      # char to integer\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))      # integer to char\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)\n",
    "      \n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1555235962110,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "cF0wLfs8GHa0",
    "outputId": "ea3aa825-d8e7-4a18-9ffb-e39dde4afce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.int)     # shape = (80000, 7, 12) \n",
    "y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.int)  # shape = (80000, 4, 12)\n",
    "\n",
    "# One-Hot encoding\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "    \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1555235963543,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "sIeS5P2eG1c5",
    "outputId": "b34c0a30-943e-4afa-c6f2-2e2a63e8e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(638720, 7, 12)\n",
      "(638720, 4, 12)\n",
      "Validation Data:\n",
      "(159680, 7, 12)\n",
      "(159680, 4, 12)\n",
      "Testing Data:\n",
      "(199601, 7, 12)\n",
      "(199601, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_ratio, random_state=0)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=test_ratio, random_state=0)\n",
    "\n",
    "# # 拆分訓練、測試、驗證資料\n",
    "# train_ratio = 0.7\n",
    "# train_split = int(TRAINING_SIZE * train_ratio)\n",
    "# indices = np.arange(len(y))\n",
    "# np.random.shuffle(indices)\n",
    "# x = x[indices]\n",
    "# y = y[indices]\n",
    "\n",
    "# # train_test_split\n",
    "# train_x = x[:train_split]\n",
    "# train_y = y[:train_split]\n",
    "# test_x = x[train_split:]\n",
    "# test_y = y[train_split:]\n",
    "\n",
    "# split_at = len(train_x) - len(train_x) // 10\n",
    "# (x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "# (y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lcKt0NOm7M6"
   },
   "outputs": [],
   "source": [
    "ctrain_x = x_train.reshape(x_train.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_x = test_x.reshape(test_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctrain_y = y_train.reshape(y_train.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_y = test_y.reshape(test_y.shape[0], -1, 1).squeeze(axis=2)\n",
    "cval_x = x_val.reshape(x_val.shape[0], -1, 1).squeeze(axis=2)\n",
    "cval_y = y_val.reshape(y_val.shape[0], -1, 1).squeeze(axis=2)\n",
    "\n",
    "# ctrain_x = train_x.reshape(train_x.shape[0], -1, 1)\n",
    "# ctest_x = train_x.reshape(test_x.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17219
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4581277,
     "status": "ok",
     "timestamp": 1555240930716,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "-ByAB5sNlvGf",
    "outputId": "df978a9b-5400-4946-e052-ff3857d21a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63000 samples, validate on 7000 samples\n",
      "Epoch 1/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 12.0866 - val_loss: 11.4487\n",
      "Epoch 2/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 11.0064 - val_loss: 10.6073\n",
      "Epoch 3/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 10.2217 - val_loss: 9.9044\n",
      "Epoch 4/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 9.5781 - val_loss: 9.3913\n",
      "Epoch 5/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 9.1624 - val_loss: 9.0625\n",
      "Epoch 6/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 8.8892 - val_loss: 8.8339\n",
      "Epoch 7/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 8.7007 - val_loss: 8.6885\n",
      "Epoch 8/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 8.5690 - val_loss: 8.5799\n",
      "Epoch 9/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 8.4647 - val_loss: 8.4845\n",
      "Epoch 10/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 8.3755 - val_loss: 8.4158\n",
      "Epoch 11/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 8.2977 - val_loss: 8.3381\n",
      "Epoch 12/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 8.2309 - val_loss: 8.2900\n",
      "Epoch 13/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 8.1719 - val_loss: 8.2144\n",
      "Epoch 14/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 8.1143 - val_loss: 8.1714\n",
      "Epoch 15/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 8.0631 - val_loss: 8.1180\n",
      "Epoch 16/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 8.0163 - val_loss: 8.0815\n",
      "Epoch 17/500\n",
      "63000/63000 [==============================] - 10s 159us/step - loss: 7.9747 - val_loss: 8.0334\n",
      "Epoch 18/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.9328 - val_loss: 8.0092\n",
      "Epoch 19/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.8984 - val_loss: 7.9645\n",
      "Epoch 20/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.8647 - val_loss: 7.9378\n",
      "Epoch 21/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.8328 - val_loss: 7.9112\n",
      "Epoch 22/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.8067 - val_loss: 7.8850\n",
      "Epoch 23/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.7812 - val_loss: 7.8615\n",
      "Epoch 24/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.7585 - val_loss: 7.8444\n",
      "Epoch 25/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.7360 - val_loss: 7.8226\n",
      "Epoch 26/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.7160 - val_loss: 7.7952\n",
      "Epoch 27/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.6971 - val_loss: 7.7780\n",
      "Epoch 28/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.6801 - val_loss: 7.7589\n",
      "Epoch 29/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 7.6637 - val_loss: 7.7526\n",
      "Epoch 30/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.6481 - val_loss: 7.7316\n",
      "Epoch 31/500\n",
      "63000/63000 [==============================] - 10s 158us/step - loss: 7.6343 - val_loss: 7.7193\n",
      "Epoch 32/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 7.6199 - val_loss: 7.7090\n",
      "Epoch 33/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.6074 - val_loss: 7.7033\n",
      "Epoch 34/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.5939 - val_loss: 7.6933\n",
      "Epoch 35/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.5827 - val_loss: 7.6799\n",
      "Epoch 36/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.5705 - val_loss: 7.6550\n",
      "Epoch 37/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.5610 - val_loss: 7.6504\n",
      "Epoch 38/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.5500 - val_loss: 7.6349\n",
      "Epoch 39/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.5395 - val_loss: 7.6323\n",
      "Epoch 40/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.5304 - val_loss: 7.6285\n",
      "Epoch 41/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.5216 - val_loss: 7.6209\n",
      "Epoch 42/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.5129 - val_loss: 7.6106\n",
      "Epoch 43/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.5055 - val_loss: 7.6051\n",
      "Epoch 44/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.4988 - val_loss: 7.6024\n",
      "Epoch 45/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.4909 - val_loss: 7.5907\n",
      "Epoch 46/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.4828 - val_loss: 7.5795\n",
      "Epoch 47/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 7.4750 - val_loss: 7.5755\n",
      "Epoch 48/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.4697 - val_loss: 7.5633\n",
      "Epoch 49/500\n",
      "63000/63000 [==============================] - 9s 135us/step - loss: 7.4620 - val_loss: 7.5642\n",
      "Epoch 50/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.4552 - val_loss: 7.5509\n",
      "Epoch 51/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.4486 - val_loss: 7.5529\n",
      "Epoch 52/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.4412 - val_loss: 7.5375\n",
      "Epoch 53/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.4361 - val_loss: 7.5406\n",
      "Epoch 54/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.4304 - val_loss: 7.5354\n",
      "Epoch 55/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.4242 - val_loss: 7.5094\n",
      "Epoch 56/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.4167 - val_loss: 7.5123\n",
      "Epoch 57/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.4116 - val_loss: 7.5180\n",
      "Epoch 58/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.4045 - val_loss: 7.5140\n",
      "Epoch 59/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.3978 - val_loss: 7.5035\n",
      "Epoch 60/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.3928 - val_loss: 7.4963\n",
      "Epoch 61/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.3849 - val_loss: 7.4931\n",
      "Epoch 62/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.3801 - val_loss: 7.4816\n",
      "Epoch 63/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.3744 - val_loss: 7.4757\n",
      "Epoch 64/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.3677 - val_loss: 7.4690\n",
      "Epoch 65/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.3616 - val_loss: 7.4671\n",
      "Epoch 66/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.3543 - val_loss: 7.4579\n",
      "Epoch 67/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.3482 - val_loss: 7.4479\n",
      "Epoch 68/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.3421 - val_loss: 7.4512\n",
      "Epoch 69/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.3365 - val_loss: 7.4375\n",
      "Epoch 70/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.3309 - val_loss: 7.4260\n",
      "Epoch 71/500\n",
      "63000/63000 [==============================] - 10s 159us/step - loss: 7.3240 - val_loss: 7.4289\n",
      "Epoch 72/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.3176 - val_loss: 7.4072\n",
      "Epoch 73/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 7.3127 - val_loss: 7.4164\n",
      "Epoch 74/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.3065 - val_loss: 7.4152\n",
      "Epoch 75/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.3025 - val_loss: 7.4133\n",
      "Epoch 76/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.2963 - val_loss: 7.3999\n",
      "Epoch 77/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.2910 - val_loss: 7.3953\n",
      "Epoch 78/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.2855 - val_loss: 7.3922\n",
      "Epoch 79/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.2807 - val_loss: 7.3831\n",
      "Epoch 80/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.2750 - val_loss: 7.3754\n",
      "Epoch 81/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.2695 - val_loss: 7.3803\n",
      "Epoch 82/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.2647 - val_loss: 7.3607\n",
      "Epoch 83/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.2596 - val_loss: 7.3667\n",
      "Epoch 84/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.2571 - val_loss: 7.3590\n",
      "Epoch 85/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.2525 - val_loss: 7.3572\n",
      "Epoch 86/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.2475 - val_loss: 7.3632\n",
      "Epoch 87/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.2449 - val_loss: 7.3531\n",
      "Epoch 88/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.2395 - val_loss: 7.3440\n",
      "Epoch 89/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.2352 - val_loss: 7.3332\n",
      "Epoch 90/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 7.2324 - val_loss: 7.3336\n",
      "Epoch 91/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 7.2286 - val_loss: 7.3217\n",
      "Epoch 92/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 7.2242 - val_loss: 7.3364\n",
      "Epoch 93/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.2235 - val_loss: 7.3329\n",
      "Epoch 94/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.2184 - val_loss: 7.3327\n",
      "Epoch 95/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.2150 - val_loss: 7.3153\n",
      "Epoch 96/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.2119 - val_loss: 7.3230\n",
      "Epoch 97/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.2089 - val_loss: 7.3272\n",
      "Epoch 98/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.2063 - val_loss: 7.3165\n",
      "Epoch 99/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.2045 - val_loss: 7.3160\n",
      "Epoch 100/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 7.2013 - val_loss: 7.3028\n",
      "Epoch 101/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.1968 - val_loss: 7.3039\n",
      "Epoch 102/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.1944 - val_loss: 7.3046\n",
      "Epoch 103/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.1924 - val_loss: 7.3094\n",
      "Epoch 104/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.1896 - val_loss: 7.3047\n",
      "Epoch 105/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.1842 - val_loss: 7.2948\n",
      "Epoch 106/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.1823 - val_loss: 7.2918\n",
      "Epoch 107/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.1815 - val_loss: 7.2972\n",
      "Epoch 108/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.1774 - val_loss: 7.2742\n",
      "Epoch 109/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.1750 - val_loss: 7.2782\n",
      "Epoch 110/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 7.1728 - val_loss: 7.2696\n",
      "Epoch 111/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.1705 - val_loss: 7.2776\n",
      "Epoch 112/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.1681 - val_loss: 7.2735\n",
      "Epoch 113/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.1666 - val_loss: 7.2688\n",
      "Epoch 114/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.1634 - val_loss: 7.2644\n",
      "Epoch 115/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.1607 - val_loss: 7.2564\n",
      "Epoch 116/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.1587 - val_loss: 7.2728\n",
      "Epoch 117/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.1567 - val_loss: 7.2750\n",
      "Epoch 118/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.1550 - val_loss: 7.2657\n",
      "Epoch 119/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.1527 - val_loss: 7.2662\n",
      "Epoch 120/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.1514 - val_loss: 7.2526\n",
      "Epoch 121/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.1474 - val_loss: 7.2517\n",
      "Epoch 122/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.1459 - val_loss: 7.2578\n",
      "Epoch 123/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.1444 - val_loss: 7.2607\n",
      "Epoch 124/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.1414 - val_loss: 7.2620\n",
      "Epoch 125/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.1405 - val_loss: 7.2604\n",
      "Epoch 126/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 7.1391 - val_loss: 7.2448\n",
      "Epoch 127/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 7.1356 - val_loss: 7.2429\n",
      "Epoch 128/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.1347 - val_loss: 7.2516\n",
      "Epoch 129/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.1326 - val_loss: 7.2455\n",
      "Epoch 130/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.1296 - val_loss: 7.2490\n",
      "Epoch 131/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.1301 - val_loss: 7.2322\n",
      "Epoch 132/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.1256 - val_loss: 7.2263\n",
      "Epoch 133/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.1254 - val_loss: 7.2297\n",
      "Epoch 134/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.1248 - val_loss: 7.2285\n",
      "Epoch 135/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 7.1219 - val_loss: 7.2300\n",
      "Epoch 136/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.1202 - val_loss: 7.2240\n",
      "Epoch 137/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.1195 - val_loss: 7.2272\n",
      "Epoch 138/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.1174 - val_loss: 7.2331\n",
      "Epoch 139/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.1153 - val_loss: 7.2316\n",
      "Epoch 140/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.1143 - val_loss: 7.2158\n",
      "Epoch 141/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.1129 - val_loss: 7.2336\n",
      "Epoch 142/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.1103 - val_loss: 7.2144\n",
      "Epoch 143/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.1102 - val_loss: 7.2239\n",
      "Epoch 144/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.1071 - val_loss: 7.2229\n",
      "Epoch 145/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 7.1073 - val_loss: 7.2136\n",
      "Epoch 146/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 7.1056 - val_loss: 7.2071\n",
      "Epoch 147/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.1041 - val_loss: 7.2307\n",
      "Epoch 148/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.1025 - val_loss: 7.2229\n",
      "Epoch 149/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.1008 - val_loss: 7.2194\n",
      "Epoch 150/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.1013 - val_loss: 7.2096\n",
      "Epoch 151/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0986 - val_loss: 7.2111\n",
      "Epoch 152/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0971 - val_loss: 7.2176\n",
      "Epoch 153/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0966 - val_loss: 7.2173\n",
      "Epoch 154/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0948 - val_loss: 7.2016\n",
      "Epoch 155/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.0931 - val_loss: 7.2106\n",
      "Epoch 156/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0920 - val_loss: 7.2226\n",
      "Epoch 157/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.0908 - val_loss: 7.2004\n",
      "Epoch 158/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 7.0911 - val_loss: 7.2016\n",
      "Epoch 159/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.0883 - val_loss: 7.1959\n",
      "Epoch 160/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.0870 - val_loss: 7.2028\n",
      "Epoch 161/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.0858 - val_loss: 7.2019\n",
      "Epoch 162/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.0866 - val_loss: 7.1876\n",
      "Epoch 163/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.0843 - val_loss: 7.1969\n",
      "Epoch 164/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.0823 - val_loss: 7.2031\n",
      "Epoch 165/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.0808 - val_loss: 7.1954\n",
      "Epoch 166/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.0812 - val_loss: 7.1868\n",
      "Epoch 167/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.0790 - val_loss: 7.1924\n",
      "Epoch 168/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 7.0789 - val_loss: 7.1928\n",
      "Epoch 169/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.0773 - val_loss: 7.1938\n",
      "Epoch 170/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.0756 - val_loss: 7.1807\n",
      "Epoch 171/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0744 - val_loss: 7.1849\n",
      "Epoch 172/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 7.0747 - val_loss: 7.1918\n",
      "Epoch 173/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.0731 - val_loss: 7.1905\n",
      "Epoch 174/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.0712 - val_loss: 7.1845\n",
      "Epoch 175/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.0707 - val_loss: 7.1821\n",
      "Epoch 176/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.0708 - val_loss: 7.1774\n",
      "Epoch 177/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.0677 - val_loss: 7.1713\n",
      "Epoch 178/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.0681 - val_loss: 7.1721\n",
      "Epoch 179/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0670 - val_loss: 7.1728\n",
      "Epoch 180/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.0646 - val_loss: 7.1911\n",
      "Epoch 181/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0649 - val_loss: 7.1737\n",
      "Epoch 182/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0643 - val_loss: 7.1703\n",
      "Epoch 183/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.0626 - val_loss: 7.1687\n",
      "Epoch 184/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0614 - val_loss: 7.1688\n",
      "Epoch 185/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.0611 - val_loss: 7.1761\n",
      "Epoch 186/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.0591 - val_loss: 7.1848\n",
      "Epoch 187/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0583 - val_loss: 7.1843\n",
      "Epoch 188/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.0580 - val_loss: 7.1674\n",
      "Epoch 189/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.0576 - val_loss: 7.1647\n",
      "Epoch 190/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0546 - val_loss: 7.1681\n",
      "Epoch 191/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.0547 - val_loss: 7.1763\n",
      "Epoch 192/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.0546 - val_loss: 7.1749\n",
      "Epoch 193/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0539 - val_loss: 7.1668\n",
      "Epoch 194/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0523 - val_loss: 7.1646\n",
      "Epoch 195/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.0504 - val_loss: 7.1700\n",
      "Epoch 196/500\n",
      "63000/63000 [==============================] - 10s 158us/step - loss: 7.0503 - val_loss: 7.1663\n",
      "Epoch 197/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 7.0486 - val_loss: 7.1781\n",
      "Epoch 198/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.0459 - val_loss: 7.1546\n",
      "Epoch 199/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 7.0462 - val_loss: 7.1617\n",
      "Epoch 200/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0464 - val_loss: 7.1525\n",
      "Epoch 201/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.0452 - val_loss: 7.1533\n",
      "Epoch 202/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.0423 - val_loss: 7.1527\n",
      "Epoch 203/500\n",
      "63000/63000 [==============================] - 10s 158us/step - loss: 7.0429 - val_loss: 7.1528\n",
      "Epoch 204/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0427 - val_loss: 7.1594\n",
      "Epoch 205/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.0409 - val_loss: 7.1544\n",
      "Epoch 206/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.0401 - val_loss: 7.1503\n",
      "Epoch 207/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.0388 - val_loss: 7.1466\n",
      "Epoch 208/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0393 - val_loss: 7.1464\n",
      "Epoch 209/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 7.0354 - val_loss: 7.1605\n",
      "Epoch 210/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 7.0360 - val_loss: 7.1436\n",
      "Epoch 211/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 7.0354 - val_loss: 7.1393\n",
      "Epoch 212/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.0333 - val_loss: 7.1364\n",
      "Epoch 213/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0334 - val_loss: 7.1499\n",
      "Epoch 214/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0325 - val_loss: 7.1376\n",
      "Epoch 215/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 7.0322 - val_loss: 7.1410\n",
      "Epoch 216/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.0293 - val_loss: 7.1428\n",
      "Epoch 217/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0297 - val_loss: 7.1644\n",
      "Epoch 218/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0281 - val_loss: 7.1417\n",
      "Epoch 219/500\n",
      "63000/63000 [==============================] - 10s 160us/step - loss: 7.0290 - val_loss: 7.1446\n",
      "Epoch 220/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0273 - val_loss: 7.1325\n",
      "Epoch 221/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0267 - val_loss: 7.1303\n",
      "Epoch 222/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0251 - val_loss: 7.1477\n",
      "Epoch 223/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0251 - val_loss: 7.1322\n",
      "Epoch 224/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.0225 - val_loss: 7.1395\n",
      "Epoch 225/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.0225 - val_loss: 7.1352\n",
      "Epoch 226/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0237 - val_loss: 7.1311\n",
      "Epoch 227/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 7.0206 - val_loss: 7.1390\n",
      "Epoch 228/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.0212 - val_loss: 7.1228\n",
      "Epoch 229/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 7.0193 - val_loss: 7.1384\n",
      "Epoch 230/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 7.0193 - val_loss: 7.1372\n",
      "Epoch 231/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 7.0176 - val_loss: 7.1395\n",
      "Epoch 232/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 7.0170 - val_loss: 7.1239\n",
      "Epoch 233/500\n",
      "63000/63000 [==============================] - 9s 135us/step - loss: 7.0161 - val_loss: 7.1249\n",
      "Epoch 234/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 7.0148 - val_loss: 7.1230\n",
      "Epoch 235/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 7.0153 - val_loss: 7.1261\n",
      "Epoch 236/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 7.0148 - val_loss: 7.1282\n",
      "Epoch 237/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0158 - val_loss: 7.1204\n",
      "Epoch 238/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.0135 - val_loss: 7.1361\n",
      "Epoch 239/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0129 - val_loss: 7.1243\n",
      "Epoch 240/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0116 - val_loss: 7.1292\n",
      "Epoch 241/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0108 - val_loss: 7.1332\n",
      "Epoch 242/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 7.0115 - val_loss: 7.1242\n",
      "Epoch 243/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 7.0104 - val_loss: 7.1265\n",
      "Epoch 244/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 7.0110 - val_loss: 7.1239\n",
      "Epoch 245/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 7.0086 - val_loss: 7.1192\n",
      "Epoch 246/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.0072 - val_loss: 7.1276\n",
      "Epoch 247/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 7.0072 - val_loss: 7.1335\n",
      "Epoch 248/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 7.0061 - val_loss: 7.1258\n",
      "Epoch 249/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 7.0060 - val_loss: 7.1262\n",
      "Epoch 250/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.0055 - val_loss: 7.1193\n",
      "Epoch 251/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 7.0063 - val_loss: 7.1338\n",
      "Epoch 252/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 7.0044 - val_loss: 7.1258\n",
      "Epoch 253/500\n",
      "63000/63000 [==============================] - 10s 160us/step - loss: 7.0035 - val_loss: 7.1280\n",
      "Epoch 254/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 7.0042 - val_loss: 7.1133\n",
      "Epoch 255/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0003 - val_loss: 7.1149\n",
      "Epoch 256/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 7.0021 - val_loss: 7.1120\n",
      "Epoch 257/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 7.0013 - val_loss: 7.1048\n",
      "Epoch 258/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9997 - val_loss: 7.1187\n",
      "Epoch 259/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9993 - val_loss: 7.1192\n",
      "Epoch 260/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9991 - val_loss: 7.1024\n",
      "Epoch 261/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9978 - val_loss: 7.1091\n",
      "Epoch 262/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9986 - val_loss: 7.1072\n",
      "Epoch 263/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9974 - val_loss: 7.1045\n",
      "Epoch 264/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9965 - val_loss: 7.1092\n",
      "Epoch 265/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9952 - val_loss: 7.1146\n",
      "Epoch 266/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9942 - val_loss: 7.0978\n",
      "Epoch 267/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9929 - val_loss: 7.1056\n",
      "Epoch 268/500\n",
      "63000/63000 [==============================] - 9s 135us/step - loss: 6.9948 - val_loss: 7.1118\n",
      "Epoch 269/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9909 - val_loss: 7.1049\n",
      "Epoch 270/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9913 - val_loss: 7.1192\n",
      "Epoch 271/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9935 - val_loss: 7.1039\n",
      "Epoch 272/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9911 - val_loss: 7.1008\n",
      "Epoch 273/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9909 - val_loss: 7.1072\n",
      "Epoch 274/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 6.9884 - val_loss: 7.1089\n",
      "Epoch 275/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9886 - val_loss: 7.0870\n",
      "Epoch 276/500\n",
      "63000/63000 [==============================] - 10s 158us/step - loss: 6.9889 - val_loss: 7.1071\n",
      "Epoch 277/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9877 - val_loss: 7.1072\n",
      "Epoch 278/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9871 - val_loss: 7.1087\n",
      "Epoch 279/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9876 - val_loss: 7.1077\n",
      "Epoch 280/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9865 - val_loss: 7.0991\n",
      "Epoch 281/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9866 - val_loss: 7.0992\n",
      "Epoch 282/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9863 - val_loss: 7.0897\n",
      "Epoch 283/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9851 - val_loss: 7.0924\n",
      "Epoch 284/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9839 - val_loss: 7.0757\n",
      "Epoch 285/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9838 - val_loss: 7.0906\n",
      "Epoch 286/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9839 - val_loss: 7.0960\n",
      "Epoch 287/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9824 - val_loss: 7.1108\n",
      "Epoch 288/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9825 - val_loss: 7.1022\n",
      "Epoch 289/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9810 - val_loss: 7.0847\n",
      "Epoch 290/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9833 - val_loss: 7.0973\n",
      "Epoch 291/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9795 - val_loss: 7.1003\n",
      "Epoch 292/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9816 - val_loss: 7.0911\n",
      "Epoch 293/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9803 - val_loss: 7.1037\n",
      "Epoch 294/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9788 - val_loss: 7.0845\n",
      "Epoch 295/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9802 - val_loss: 7.0978\n",
      "Epoch 296/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9790 - val_loss: 7.0903\n",
      "Epoch 297/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9782 - val_loss: 7.0911\n",
      "Epoch 298/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9788 - val_loss: 7.1020\n",
      "Epoch 299/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9779 - val_loss: 7.0951\n",
      "Epoch 300/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9773 - val_loss: 7.0888\n",
      "Epoch 301/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9762 - val_loss: 7.0815\n",
      "Epoch 302/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9759 - val_loss: 7.0988\n",
      "Epoch 303/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9752 - val_loss: 7.0936\n",
      "Epoch 304/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9738 - val_loss: 7.0929\n",
      "Epoch 305/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9765 - val_loss: 7.0838\n",
      "Epoch 306/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9723 - val_loss: 7.0859\n",
      "Epoch 307/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9730 - val_loss: 7.0812\n",
      "Epoch 308/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9731 - val_loss: 7.0738\n",
      "Epoch 309/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9718 - val_loss: 7.0819\n",
      "Epoch 310/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9714 - val_loss: 7.1041\n",
      "Epoch 311/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9713 - val_loss: 7.0834\n",
      "Epoch 312/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9684 - val_loss: 7.0815\n",
      "Epoch 313/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9706 - val_loss: 7.0779\n",
      "Epoch 314/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9711 - val_loss: 7.0751\n",
      "Epoch 315/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9681 - val_loss: 7.0948\n",
      "Epoch 316/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9705 - val_loss: 7.0769\n",
      "Epoch 317/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9672 - val_loss: 7.0878\n",
      "Epoch 318/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9680 - val_loss: 7.0825\n",
      "Epoch 319/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9674 - val_loss: 7.0804\n",
      "Epoch 320/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9676 - val_loss: 7.0794\n",
      "Epoch 321/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9671 - val_loss: 7.0745\n",
      "Epoch 322/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9658 - val_loss: 7.0726\n",
      "Epoch 323/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9655 - val_loss: 7.0777\n",
      "Epoch 324/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9658 - val_loss: 7.0761\n",
      "Epoch 325/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9650 - val_loss: 7.0850\n",
      "Epoch 326/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9639 - val_loss: 7.0819\n",
      "Epoch 327/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9644 - val_loss: 7.0761\n",
      "Epoch 328/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9662 - val_loss: 7.0724\n",
      "Epoch 329/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9639 - val_loss: 7.0877\n",
      "Epoch 330/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9634 - val_loss: 7.0768\n",
      "Epoch 331/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 6.9638 - val_loss: 7.0679\n",
      "Epoch 332/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 6.9631 - val_loss: 7.0785\n",
      "Epoch 333/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9624 - val_loss: 7.0806\n",
      "Epoch 334/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9625 - val_loss: 7.0697\n",
      "Epoch 335/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9614 - val_loss: 7.0764\n",
      "Epoch 336/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9609 - val_loss: 7.0672\n",
      "Epoch 337/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9629 - val_loss: 7.0972\n",
      "Epoch 338/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9612 - val_loss: 7.0704\n",
      "Epoch 339/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9603 - val_loss: 7.0627\n",
      "Epoch 340/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9595 - val_loss: 7.0654\n",
      "Epoch 341/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9605 - val_loss: 7.0851\n",
      "Epoch 342/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9603 - val_loss: 7.0684\n",
      "Epoch 343/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9602 - val_loss: 7.0666\n",
      "Epoch 344/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9595 - val_loss: 7.0650\n",
      "Epoch 345/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 6.9596 - val_loss: 7.0714\n",
      "Epoch 346/500\n",
      "63000/63000 [==============================] - 8s 132us/step - loss: 6.9587 - val_loss: 7.0691\n",
      "Epoch 347/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 6.9574 - val_loss: 7.0788\n",
      "Epoch 348/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9572 - val_loss: 7.0734\n",
      "Epoch 349/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9578 - val_loss: 7.0693\n",
      "Epoch 350/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9566 - val_loss: 7.0650\n",
      "Epoch 351/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9573 - val_loss: 7.0831\n",
      "Epoch 352/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9570 - val_loss: 7.0616\n",
      "Epoch 353/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9559 - val_loss: 7.0578\n",
      "Epoch 354/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9547 - val_loss: 7.0654\n",
      "Epoch 355/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 6.9540 - val_loss: 7.0640\n",
      "Epoch 356/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9533 - val_loss: 7.0654\n",
      "Epoch 357/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9536 - val_loss: 7.0777\n",
      "Epoch 358/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9539 - val_loss: 7.0500\n",
      "Epoch 359/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9522 - val_loss: 7.0561\n",
      "Epoch 360/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9527 - val_loss: 7.0613\n",
      "Epoch 361/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 6.9527 - val_loss: 7.0507\n",
      "Epoch 362/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9532 - val_loss: 7.0686\n",
      "Epoch 363/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9524 - val_loss: 7.0624\n",
      "Epoch 364/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9530 - val_loss: 7.0662\n",
      "Epoch 365/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9526 - val_loss: 7.0557\n",
      "Epoch 366/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9502 - val_loss: 7.0606\n",
      "Epoch 367/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9499 - val_loss: 7.0575\n",
      "Epoch 368/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9507 - val_loss: 7.0613\n",
      "Epoch 369/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9500 - val_loss: 7.0599\n",
      "Epoch 370/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9497 - val_loss: 7.0761\n",
      "Epoch 371/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9504 - val_loss: 7.0757\n",
      "Epoch 372/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9491 - val_loss: 7.0601\n",
      "Epoch 373/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9483 - val_loss: 7.0558\n",
      "Epoch 374/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9499 - val_loss: 7.0648\n",
      "Epoch 375/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9489 - val_loss: 7.0643\n",
      "Epoch 376/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9477 - val_loss: 7.0713\n",
      "Epoch 377/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9469 - val_loss: 7.0628\n",
      "Epoch 378/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9478 - val_loss: 7.0684\n",
      "Epoch 379/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9473 - val_loss: 7.0570\n",
      "Epoch 380/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9452 - val_loss: 7.0534\n",
      "Epoch 381/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9452 - val_loss: 7.0545\n",
      "Epoch 382/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9462 - val_loss: 7.0554\n",
      "Epoch 383/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9465 - val_loss: 7.0565\n",
      "Epoch 384/500\n",
      "63000/63000 [==============================] - 8s 132us/step - loss: 6.9447 - val_loss: 7.0563\n",
      "Epoch 385/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 6.9457 - val_loss: 7.0655\n",
      "Epoch 386/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9454 - val_loss: 7.0551\n",
      "Epoch 387/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9444 - val_loss: 7.0602\n",
      "Epoch 388/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 6.9443 - val_loss: 7.0663\n",
      "Epoch 389/500\n",
      "63000/63000 [==============================] - 10s 161us/step - loss: 6.9451 - val_loss: 7.0401\n",
      "Epoch 390/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9448 - val_loss: 7.0510\n",
      "Epoch 391/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9435 - val_loss: 7.0485\n",
      "Epoch 392/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9433 - val_loss: 7.0437\n",
      "Epoch 393/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9434 - val_loss: 7.0565\n",
      "Epoch 394/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9427 - val_loss: 7.0536\n",
      "Epoch 395/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9422 - val_loss: 7.0615\n",
      "Epoch 396/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9429 - val_loss: 7.0532\n",
      "Epoch 397/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9421 - val_loss: 7.0549\n",
      "Epoch 398/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9407 - val_loss: 7.0547\n",
      "Epoch 399/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9412 - val_loss: 7.0434\n",
      "Epoch 400/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9406 - val_loss: 7.0433\n",
      "Epoch 401/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9404 - val_loss: 7.0532\n",
      "Epoch 402/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9396 - val_loss: 7.0402\n",
      "Epoch 403/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9409 - val_loss: 7.0481\n",
      "Epoch 404/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9380 - val_loss: 7.0527\n",
      "Epoch 405/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9394 - val_loss: 7.0424\n",
      "Epoch 406/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9406 - val_loss: 7.0475\n",
      "Epoch 407/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9385 - val_loss: 7.0468\n",
      "Epoch 408/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9401 - val_loss: 7.0507\n",
      "Epoch 409/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9382 - val_loss: 7.0476\n",
      "Epoch 410/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9383 - val_loss: 7.0419\n",
      "Epoch 411/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9375 - val_loss: 7.0479\n",
      "Epoch 412/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 6.9376 - val_loss: 7.0569\n",
      "Epoch 413/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9378 - val_loss: 7.0466\n",
      "Epoch 414/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9376 - val_loss: 7.0448\n",
      "Epoch 415/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9358 - val_loss: 7.0497\n",
      "Epoch 416/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9366 - val_loss: 7.0500\n",
      "Epoch 417/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9354 - val_loss: 7.0428\n",
      "Epoch 418/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9367 - val_loss: 7.0579\n",
      "Epoch 419/500\n",
      "63000/63000 [==============================] - 9s 138us/step - loss: 6.9345 - val_loss: 7.0454\n",
      "Epoch 420/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9356 - val_loss: 7.0566\n",
      "Epoch 421/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9343 - val_loss: 7.0490\n",
      "Epoch 422/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9332 - val_loss: 7.0474\n",
      "Epoch 423/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9347 - val_loss: 7.0458\n",
      "Epoch 424/500\n",
      "63000/63000 [==============================] - 8s 133us/step - loss: 6.9338 - val_loss: 7.0530\n",
      "Epoch 425/500\n",
      "63000/63000 [==============================] - 9s 135us/step - loss: 6.9341 - val_loss: 7.0535\n",
      "Epoch 426/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9327 - val_loss: 7.0275\n",
      "Epoch 427/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9340 - val_loss: 7.0490\n",
      "Epoch 428/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9327 - val_loss: 7.0444\n",
      "Epoch 429/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9329 - val_loss: 7.0382\n",
      "Epoch 430/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 6.9333 - val_loss: 7.0396\n",
      "Epoch 431/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9323 - val_loss: 7.0501\n",
      "Epoch 432/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9299 - val_loss: 7.0320\n",
      "Epoch 433/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9302 - val_loss: 7.0465\n",
      "Epoch 434/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9336 - val_loss: 7.0449\n",
      "Epoch 435/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 6.9314 - val_loss: 7.0419\n",
      "Epoch 436/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9323 - val_loss: 7.0388\n",
      "Epoch 437/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9293 - val_loss: 7.0306\n",
      "Epoch 438/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9282 - val_loss: 7.0435\n",
      "Epoch 439/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9288 - val_loss: 7.0432\n",
      "Epoch 440/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9286 - val_loss: 7.0339\n",
      "Epoch 441/500\n",
      "63000/63000 [==============================] - 9s 140us/step - loss: 6.9311 - val_loss: 7.0354\n",
      "Epoch 442/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9290 - val_loss: 7.0352\n",
      "Epoch 443/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9291 - val_loss: 7.0272\n",
      "Epoch 444/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9291 - val_loss: 7.0346\n",
      "Epoch 445/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9272 - val_loss: 7.0318\n",
      "Epoch 446/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9279 - val_loss: 7.0303\n",
      "Epoch 447/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9285 - val_loss: 7.0374\n",
      "Epoch 448/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9249 - val_loss: 7.0361\n",
      "Epoch 449/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9261 - val_loss: 7.0450\n",
      "Epoch 450/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9259 - val_loss: 7.0377\n",
      "Epoch 451/500\n",
      "63000/63000 [==============================] - 9s 150us/step - loss: 6.9256 - val_loss: 7.0364\n",
      "Epoch 452/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9257 - val_loss: 7.0221\n",
      "Epoch 453/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9253 - val_loss: 7.0291\n",
      "Epoch 454/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9249 - val_loss: 7.0249\n",
      "Epoch 455/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9251 - val_loss: 7.0264\n",
      "Epoch 456/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9230 - val_loss: 7.0338\n",
      "Epoch 457/500\n",
      "63000/63000 [==============================] - 9s 151us/step - loss: 6.9236 - val_loss: 7.0389\n",
      "Epoch 458/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9240 - val_loss: 7.0400\n",
      "Epoch 459/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9225 - val_loss: 7.0322\n",
      "Epoch 460/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9234 - val_loss: 7.0417\n",
      "Epoch 461/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9235 - val_loss: 7.0188\n",
      "Epoch 462/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9228 - val_loss: 7.0352\n",
      "Epoch 463/500\n",
      "63000/63000 [==============================] - 9s 137us/step - loss: 6.9222 - val_loss: 7.0220\n",
      "Epoch 464/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9214 - val_loss: 7.0241\n",
      "Epoch 465/500\n",
      "63000/63000 [==============================] - 10s 151us/step - loss: 6.9225 - val_loss: 7.0306\n",
      "Epoch 466/500\n",
      "63000/63000 [==============================] - 10s 157us/step - loss: 6.9214 - val_loss: 7.0218\n",
      "Epoch 467/500\n",
      "63000/63000 [==============================] - 10s 156us/step - loss: 6.9206 - val_loss: 7.0295\n",
      "Epoch 468/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9212 - val_loss: 7.0228\n",
      "Epoch 469/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9206 - val_loss: 7.0319\n",
      "Epoch 470/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9200 - val_loss: 7.0278\n",
      "Epoch 471/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9209 - val_loss: 7.0271\n",
      "Epoch 472/500\n",
      "63000/63000 [==============================] - 10s 154us/step - loss: 6.9191 - val_loss: 7.0386\n",
      "Epoch 473/500\n",
      "63000/63000 [==============================] - 10s 153us/step - loss: 6.9195 - val_loss: 7.0288\n",
      "Epoch 474/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9188 - val_loss: 7.0345\n",
      "Epoch 475/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9193 - val_loss: 7.0307\n",
      "Epoch 476/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9184 - val_loss: 7.0202\n",
      "Epoch 477/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9185 - val_loss: 7.0263\n",
      "Epoch 478/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9196 - val_loss: 7.0193\n",
      "Epoch 479/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9188 - val_loss: 7.0316\n",
      "Epoch 480/500\n",
      "63000/63000 [==============================] - 9s 147us/step - loss: 6.9178 - val_loss: 7.0179\n",
      "Epoch 481/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9183 - val_loss: 7.0322\n",
      "Epoch 482/500\n",
      "63000/63000 [==============================] - 9s 142us/step - loss: 6.9179 - val_loss: 7.0199\n",
      "Epoch 483/500\n",
      "63000/63000 [==============================] - 9s 143us/step - loss: 6.9181 - val_loss: 7.0228\n",
      "Epoch 484/500\n",
      "63000/63000 [==============================] - 9s 146us/step - loss: 6.9161 - val_loss: 7.0126\n",
      "Epoch 485/500\n",
      "63000/63000 [==============================] - 9s 141us/step - loss: 6.9173 - val_loss: 7.0133\n",
      "Epoch 486/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9169 - val_loss: 7.0245\n",
      "Epoch 487/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9149 - val_loss: 7.0222\n",
      "Epoch 488/500\n",
      "63000/63000 [==============================] - 10s 152us/step - loss: 6.9165 - val_loss: 7.0184\n",
      "Epoch 489/500\n",
      "63000/63000 [==============================] - 10s 155us/step - loss: 6.9153 - val_loss: 7.0267\n",
      "Epoch 490/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9152 - val_loss: 7.0348\n",
      "Epoch 491/500\n",
      "63000/63000 [==============================] - 9s 149us/step - loss: 6.9150 - val_loss: 7.0322\n",
      "Epoch 492/500\n",
      "63000/63000 [==============================] - 9s 144us/step - loss: 6.9164 - val_loss: 7.0151\n",
      "Epoch 493/500\n",
      "63000/63000 [==============================] - 9s 148us/step - loss: 6.9165 - val_loss: 7.0148\n",
      "Epoch 494/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9155 - val_loss: 7.0362\n",
      "Epoch 495/500\n",
      "63000/63000 [==============================] - 9s 145us/step - loss: 6.9151 - val_loss: 7.0176\n",
      "Epoch 496/500\n",
      "63000/63000 [==============================] - 9s 136us/step - loss: 6.9152 - val_loss: 7.0099\n",
      "Epoch 497/500\n",
      "63000/63000 [==============================] - 9s 135us/step - loss: 6.9137 - val_loss: 7.0177\n",
      "Epoch 498/500\n",
      "63000/63000 [==============================] - 8s 134us/step - loss: 6.9149 - val_loss: 7.0239\n",
      "Epoch 499/500\n",
      "63000/63000 [==============================] - 8s 135us/step - loss: 6.9134 - val_loss: 7.0272\n",
      "Epoch 500/500\n",
      "63000/63000 [==============================] - 9s 139us/step - loss: 6.9137 - val_loss: 7.0404\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(84,))\n",
    "w1 = Dense(150, activation='relu', name='weight1')\n",
    "dense1 = w1(input1)\n",
    "w2 = Dense(48, activation='softmax', name='weight2')\n",
    "output1 = w2(dense1)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output1])\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy'])\n",
    "model.fit(x=[ctrain_x], y=[ctrain_y], validation_data=[cval_x, cval_y], epochs=500)\n",
    "\n",
    "predicted = model.predict(ctest_x)\n",
    "# cpredicted = np.concatenate([predicted[0], predicted[1], predicted[2], predicted[3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1555245867977,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "LQoBhMlcvHk2",
    "outputId": "0420be05-5dbc-4221-f5cc-a184627140ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(ctest_x).reshape(ctest_x.shape[0], 4, 12)\n",
    "print(predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1555245897103,
     "user": {
      "displayName": "Yi-Wei Cheng",
      "photoUrl": "https://lh5.googleusercontent.com/-ffkQUpJGcMA/AAAAAAAAAAI/AAAAAAAAJeQ/_gf8M7OJn9E/s64/photo.jpg",
      "userId": "00378559322257653042"
     },
     "user_tz": -480
    },
    "id": "V3cYANxqWj-f",
    "outputId": "f60e086c-b2a1-41af-8826-fc489466434e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x: 464+38 \n",
      "test_y: 502 \n",
      "predicted: 502 \n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "print('test_x:', ctable.decode(test_x[i]))\n",
    "print('test_y:', ctable.decode(test_y[i]))\n",
    "print('predicted:', ctable.decode(predicted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1UNhTdGCSy8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OlpMISgnqxO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Adder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
