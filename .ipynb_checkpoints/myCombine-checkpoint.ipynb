{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合併加法器與減法器\n",
    "# 本程式為建構一深度學習模型，可同時處理加法與減法，輸入一段三位數 +或- 三位數之算式，計算及答案。 並比較不同神經元個數、Epoch次數之影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匯入所需library，主要使用keras建立神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自行生成加法和減法算式資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "DIGITS = 3\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+- '\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "\n",
    "print('Generating data...')\n",
    "\n",
    "for a in range(0, 1000):\n",
    "    for b in range(0, 1000):\n",
    "        # 不論 a,b誰大，都要產生加法運算資料\n",
    "        q = '{}+{}'.format(str(a), str(b))    # 將 +號 插進兩數字中，產生數學式的字串\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a + b)\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        questions.append(query)\n",
    "        expected.append(ans)\n",
    "        if a > b:   # 若a大於b，才產生減法運算資料\n",
    "            q = '{}-{}'.format(str(a), str(b))    # 將 -號 插進兩數字中，產生數學式的字串\n",
    "            query = q + ' ' * (MAXLEN - len(q))\n",
    "            ans = str(a - b)\n",
    "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "            questions.append(query)\n",
    "            expected.append(ans)\n",
    "        \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))      # char to integer\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))      # integer to char\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)\n",
    "      \n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將產生好的資料化為 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.int)  \n",
    "y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.int)\n",
    "\n",
    "# One-Hot encoding\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "    \n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分訓練、驗證、測試資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(959680, 7, 13)\n",
      "(959680, 4, 13)\n",
      "Validation Data:\n",
      "(239920, 7, 13)\n",
      "(239920, 4, 13)\n",
      "Testing Data:\n",
      "(299900, 7, 13)\n",
      "(299900, 4, 13)\n"
     ]
    }
   ],
   "source": [
    "# 拆分訓練、驗證、測試資料集\n",
    "test_ratio = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_ratio, random_state=0)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=test_ratio, random_state=0)\n",
    "\n",
    "print('Training Data:')\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrain_x = train_x.reshape(train_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_x = test_x.reshape(test_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctrain_y = train_y.reshape(train_y.shape[0], -1, 1).squeeze(axis=2)\n",
    "ctest_y = test_y.reshape(test_y.shape[0], -1, 1).squeeze(axis=2)\n",
    "cvalid_x = valid_x.reshape(valid_x.shape[0], -1, 1).squeeze(axis=2)\n",
    "cvalid_y = valid_y.reshape(valid_y.shape[0], -1, 1).squeeze(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定訓練10個 epochs, 以不同的隱藏層神經元個數訓練，比較 accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 10.7399 - acc: 0.3197 - val_loss: 10.0423 - val_acc: 0.2606\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 9.9065 - acc: 0.2637 - val_loss: 9.8095 - val_acc: 0.2718\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 9.7503 - acc: 0.2614 - val_loss: 9.7023 - val_acc: 0.2372\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 9.6730 - acc: 0.2614 - val_loss: 9.6397 - val_acc: 0.2516\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 9.6165 - acc: 0.2625 - val_loss: 9.5892 - val_acc: 0.2767\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 9.5764 - acc: 0.2630 - val_loss: 9.5634 - val_acc: 0.2621\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 9.5526 - acc: 0.2632 - val_loss: 9.5391 - val_acc: 0.2697\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 9.5324 - acc: 0.2631 - val_loss: 9.5173 - val_acc: 0.2658\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 9.5085 - acc: 0.2626 - val_loss: 9.4843 - val_acc: 0.3059\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 9.4765 - acc: 0.2602 - val_loss: 9.4621 - val_acc: 0.2756\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 49s 51us/step - loss: 9.8512 - acc: 0.2511 - val_loss: 9.0752 - val_acc: 0.2328\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.8805 - acc: 0.2316 - val_loss: 8.7193 - val_acc: 0.2509\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.6209 - acc: 0.2345 - val_loss: 8.5360 - val_acc: 0.2881\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.4929 - acc: 0.2370 - val_loss: 8.4475 - val_acc: 0.2458\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.4358 - acc: 0.2394 - val_loss: 8.4135 - val_acc: 0.2186\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.3939 - acc: 0.2423 - val_loss: 8.3722 - val_acc: 0.2459\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.3612 - acc: 0.2456 - val_loss: 8.3547 - val_acc: 0.2157\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.3329 - acc: 0.2474 - val_loss: 8.3290 - val_acc: 0.2038\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.3118 - acc: 0.2485 - val_loss: 8.3124 - val_acc: 0.2947\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 8.2910 - acc: 0.2488 - val_loss: 8.2925 - val_acc: 0.2844\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 51s 54us/step - loss: 9.4550 - acc: 0.2468 - val_loss: 8.5374 - val_acc: 0.2245\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 8.3472 - acc: 0.2469 - val_loss: 8.2140 - val_acc: 0.2546\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 8.1257 - acc: 0.2539 - val_loss: 8.0479 - val_acc: 0.2650\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 8.0035 - acc: 0.2582 - val_loss: 7.9556 - val_acc: 0.2302\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 51s 54us/step - loss: 7.9220 - acc: 0.2610 - val_loss: 7.8814 - val_acc: 0.2742\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 7.8577 - acc: 0.2609 - val_loss: 7.8255 - val_acc: 0.2476\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 52s 54us/step - loss: 7.8128 - acc: 0.2606 - val_loss: 7.7950 - val_acc: 0.2309\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 7.7754 - acc: 0.2596 - val_loss: 7.7871 - val_acc: 0.2648\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 51s 53us/step - loss: 7.7450 - acc: 0.2586 - val_loss: 7.7292 - val_acc: 0.1935\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 52s 54us/step - loss: 7.7190 - acc: 0.2569 - val_loss: 7.7041 - val_acc: 0.2207\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 55s 57us/step - loss: 9.0848 - acc: 0.2399 - val_loss: 8.1774 - val_acc: 0.2131\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 55s 57us/step - loss: 7.9535 - acc: 0.2462 - val_loss: 7.7997 - val_acc: 0.2190\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 54s 57us/step - loss: 7.7101 - acc: 0.2497 - val_loss: 7.6355 - val_acc: 0.2693\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 55s 57us/step - loss: 7.5860 - acc: 0.2490 - val_loss: 7.5479 - val_acc: 0.2861\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 54s 57us/step - loss: 7.5063 - acc: 0.2486 - val_loss: 7.4819 - val_acc: 0.1869\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 55s 57us/step - loss: 7.4446 - acc: 0.2475 - val_loss: 7.4353 - val_acc: 0.2545\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 54s 57us/step - loss: 7.4029 - acc: 0.2479 - val_loss: 7.3811 - val_acc: 0.2630\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 55s 57us/step - loss: 7.3687 - acc: 0.2472 - val_loss: 7.3468 - val_acc: 0.2728\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.3389 - acc: 0.2470 - val_loss: 7.3345 - val_acc: 0.2175\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 7.3164 - acc: 0.2469 - val_loss: 7.3133 - val_acc: 0.2428\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 8.9321 - acc: 0.2403 - val_loss: 7.9642 - val_acc: 0.2418\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.7478 - acc: 0.2499 - val_loss: 7.6079 - val_acc: 0.2412\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 46s 47us/step - loss: 7.5197 - acc: 0.2501 - val_loss: 7.4646 - val_acc: 0.2908\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.4118 - acc: 0.2495 - val_loss: 7.3725 - val_acc: 0.2585\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.3415 - acc: 0.2490 - val_loss: 7.3266 - val_acc: 0.2525\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 46s 47us/step - loss: 7.2873 - acc: 0.2483 - val_loss: 7.2672 - val_acc: 0.2334\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.2474 - acc: 0.2483 - val_loss: 7.2312 - val_acc: 0.2548\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 46s 47us/step - loss: 7.2154 - acc: 0.2487 - val_loss: 7.2007 - val_acc: 0.2708\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.1897 - acc: 0.2483 - val_loss: 7.1799 - val_acc: 0.2558\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 7.1682 - acc: 0.2483 - val_loss: 7.1664 - val_acc: 0.2164\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 49s 51us/step - loss: 8.7071 - acc: 0.2410 - val_loss: 7.7524 - val_acc: 0.2530\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 7.5656 - acc: 0.2521 - val_loss: 7.4301 - val_acc: 0.3038\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 49s 51us/step - loss: 7.3506 - acc: 0.2520 - val_loss: 7.2795 - val_acc: 0.2439\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 7.2441 - acc: 0.2515 - val_loss: 7.2097 - val_acc: 0.3228\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 7.1775 - acc: 0.2513 - val_loss: 7.1761 - val_acc: 0.2468\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 49s 51us/step - loss: 7.1293 - acc: 0.2507 - val_loss: 7.1153 - val_acc: 0.2895\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959680/959680 [==============================] - 48s 50us/step - loss: 7.0890 - acc: 0.2509 - val_loss: 7.0705 - val_acc: 0.2206\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 7.0577 - acc: 0.2503 - val_loss: 7.0500 - val_acc: 0.3257\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 7.0339 - acc: 0.2496 - val_loss: 7.0248 - val_acc: 0.2888\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 37s 38us/step - loss: 7.0155 - acc: 0.2506 - val_loss: 7.0080 - val_acc: 0.3377\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 40s 42us/step - loss: 8.5414 - acc: 0.2444 - val_loss: 7.5580 - val_acc: 0.2326\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 7.3718 - acc: 0.2537 - val_loss: 7.2334 - val_acc: 0.2349\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 7.1657 - acc: 0.2519 - val_loss: 7.1140 - val_acc: 0.2738\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 7.0622 - acc: 0.2501 - val_loss: 7.0419 - val_acc: 0.2421\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.9933 - acc: 0.2487 - val_loss: 6.9658 - val_acc: 0.2503\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.9407 - acc: 0.2486 - val_loss: 6.9248 - val_acc: 0.2323\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.9007 - acc: 0.2474 - val_loss: 6.8924 - val_acc: 0.2140\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.8694 - acc: 0.2478 - val_loss: 6.8692 - val_acc: 0.1840\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.8422 - acc: 0.2474 - val_loss: 6.8223 - val_acc: 0.2745\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.8203 - acc: 0.2476 - val_loss: 6.8256 - val_acc: 0.2090\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 8.4092 - acc: 0.2482 - val_loss: 7.4671 - val_acc: 0.3189\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 42s 43us/step - loss: 7.2736 - acc: 0.2537 - val_loss: 7.1480 - val_acc: 0.2496\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 42s 43us/step - loss: 7.0743 - acc: 0.2515 - val_loss: 7.0123 - val_acc: 0.2956\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 6.9773 - acc: 0.2501 - val_loss: 6.9467 - val_acc: 0.2545\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 6.9161 - acc: 0.2493 - val_loss: 6.9069 - val_acc: 0.2506\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 42s 43us/step - loss: 6.8706 - acc: 0.2490 - val_loss: 6.8520 - val_acc: 0.2371\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 6.8342 - acc: 0.2485 - val_loss: 6.8192 - val_acc: 0.2752\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 6.8020 - acc: 0.2475 - val_loss: 6.7931 - val_acc: 0.2491\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 42s 43us/step - loss: 6.7713 - acc: 0.2474 - val_loss: 6.7623 - val_acc: 0.2603\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 42s 43us/step - loss: 6.7444 - acc: 0.2468 - val_loss: 6.7269 - val_acc: 0.2290\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 8.3115 - acc: 0.2474 - val_loss: 7.3561 - val_acc: 0.2834\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 7.1653 - acc: 0.2525 - val_loss: 7.0467 - val_acc: 0.3141\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.9627 - acc: 0.2504 - val_loss: 6.9069 - val_acc: 0.2416\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 6.8634 - acc: 0.2485 - val_loss: 6.8309 - val_acc: 0.2945\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.7971 - acc: 0.2472 - val_loss: 6.7672 - val_acc: 0.2521\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 6.7425 - acc: 0.2448 - val_loss: 6.7296 - val_acc: 0.2659\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 6.7075 - acc: 0.2451 - val_loss: 6.6872 - val_acc: 0.2821\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.6803 - acc: 0.2445 - val_loss: 6.6716 - val_acc: 0.1984\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.6566 - acc: 0.2441 - val_loss: 6.6487 - val_acc: 0.2554\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 6.6380 - acc: 0.2443 - val_loss: 6.6421 - val_acc: 0.2838\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 8.1720 - acc: 0.2452 - val_loss: 7.1887 - val_acc: 0.2786\n",
      "Epoch 2/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 7.0145 - acc: 0.2480 - val_loss: 6.8989 - val_acc: 0.2517\n",
      "Epoch 3/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.8319 - acc: 0.2469 - val_loss: 6.7745 - val_acc: 0.2539\n",
      "Epoch 4/10\n",
      "959680/959680 [==============================] - 46s 47us/step - loss: 6.7443 - acc: 0.2463 - val_loss: 6.7169 - val_acc: 0.2331\n",
      "Epoch 5/10\n",
      "959680/959680 [==============================] - 46s 47us/step - loss: 6.6937 - acc: 0.2461 - val_loss: 6.6795 - val_acc: 0.2370\n",
      "Epoch 6/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.6544 - acc: 0.2469 - val_loss: 6.6394 - val_acc: 0.2518\n",
      "Epoch 7/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.6245 - acc: 0.2465 - val_loss: 6.6227 - val_acc: 0.2458\n",
      "Epoch 8/10\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.6007 - acc: 0.2459 - val_loss: 6.5873 - val_acc: 0.2198\n",
      "Epoch 9/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5808 - acc: 0.2457 - val_loss: 6.5754 - val_acc: 0.2294\n",
      "Epoch 10/10\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5624 - acc: 0.2451 - val_loss: 6.5666 - val_acc: 0.2435\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for n_neurons in range(50, 501, 50):\n",
    "    input1 = Input(shape=(91,))\n",
    "    w1 = Dense(n_neurons, activation='relu', name='weight1')\n",
    "    dense1 = w1(input1)\n",
    "    w2 = Dense(52, activation='softmax', name='weight2')\n",
    "    output1 = w2(dense1)\n",
    "\n",
    "    model = Model(inputs=[input1], outputs=[output1])\n",
    "    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    h = model.fit(x=[ctrain_x], y=[ctrain_y], validation_data=[cvalid_x, cvalid_y], epochs=10)\n",
    "    \n",
    "    # 預測測試集\n",
    "    predicted = model.predict(ctest_x).reshape(ctest_x.shape[0], 4, 13)\n",
    "    \n",
    "    # 將預測結果(one-hot編碼)轉回一般數值\n",
    "    labels = []\n",
    "    ans = []\n",
    "    for i in range(0, len(test_y)):\n",
    "        labels.append(ctable.decode(test_y[i]))\n",
    "        ans.append(ctable.decode(predicted[i]))\n",
    "    # 計算測試資料正確率\n",
    "    acc = accuracy_score(ans, labels)\n",
    "    acc_list.append(acc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下圖可發現，隨著神經元個數變多，accuracy持續成長，並逐漸緩慢下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "plt.rcParams['font.sans-serif']=['SimHei']   # 設定中文字體\n",
    "plt.title(u'不同神經元數對accuracy之影響(固定訓練10個epoch)')\n",
    "plt.xlabel('number of neurons')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.plot(np.arange(50, 501, 50), acc_list, label='test_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定神經元個數為300，比較訓練不同 epoch 次數之影響，並畫出訓練過程loss與accuracy之變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 40s 42us/step - loss: 8.7018 - val_loss: 7.7178\n",
      "accuracy:  0.470961153717906\n",
      "Epoch 2/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 72s 75us/step - loss: 7.5092 - val_loss: 7.3656\n",
      "accuracy:  0.5686312104034679\n",
      "Epoch 3/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 7.2907 - val_loss: 7.2202\n",
      "accuracy:  0.6115746915638546\n",
      "Epoch 4/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 84s 88us/step - loss: 7.1892 - val_loss: 7.1569\n",
      "accuracy:  0.6299224741580527\n",
      "Epoch 5/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 86s 90us/step - loss: 7.1210 - val_loss: 7.0942\n",
      "accuracy:  0.6446773924641547\n",
      "Epoch 6/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 82s 86us/step - loss: 7.0732 - val_loss: 7.0683\n",
      "accuracy:  0.6586487162387462\n",
      "Epoch 7/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 85us/step - loss: 7.0349 - val_loss: 7.0054\n",
      "accuracy:  0.6704193064354785\n",
      "Epoch 8/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 90s 94us/step - loss: 7.0074 - val_loss: 7.0009\n",
      "accuracy:  0.6725533511170391\n",
      "Epoch 9/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 90s 93us/step - loss: 6.9851 - val_loss: 6.9871\n",
      "accuracy:  0.6799808269423141\n",
      "Epoch 10/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 83us/step - loss: 6.9682 - val_loss: 6.9583\n",
      "accuracy:  0.6841155385128376\n",
      "Epoch 11/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.9525 - val_loss: 6.9516\n",
      "accuracy:  0.6940980326775592\n",
      "Epoch 12/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 83s 86us/step - loss: 6.9392 - val_loss: 6.9268\n",
      "accuracy:  0.6976325441813938\n",
      "Epoch 13/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 85us/step - loss: 6.9267 - val_loss: 6.9297\n",
      "accuracy:  0.6928642880960321\n",
      "Epoch 14/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 82us/step - loss: 6.9149 - val_loss: 6.9064\n",
      "accuracy:  0.7016338779593198\n",
      "Epoch 15/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 85us/step - loss: 6.9048 - val_loss: 6.9036\n",
      "accuracy:  0.7064188062687563\n",
      "Epoch 16/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 83s 87us/step - loss: 6.8935 - val_loss: 6.8973\n",
      "accuracy:  0.7037804268089363\n",
      "Epoch 17/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 84s 87us/step - loss: 6.8808 - val_loss: 6.8773\n",
      "accuracy:  0.7115080026675559\n",
      "Epoch 18/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 82us/step - loss: 6.8692 - val_loss: 6.8754\n",
      "accuracy:  0.7100491830610204\n",
      "Epoch 19/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 83s 86us/step - loss: 6.8556 - val_loss: 6.8610\n",
      "accuracy:  0.7188187729243081\n",
      "Epoch 20/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 83s 86us/step - loss: 6.8450 - val_loss: 6.8500\n",
      "accuracy:  0.7222907635878626\n",
      "Epoch 21/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.8359 - val_loss: 6.8337\n",
      "accuracy:  0.7246207069023007\n",
      "Epoch 22/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.8284 - val_loss: 6.8256\n",
      "accuracy:  0.7259669889963322\n",
      "Epoch 23/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.8205 - val_loss: 6.7965\n",
      "accuracy:  0.7331027009003\n",
      "Epoch 24/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.8141 - val_loss: 6.8092\n",
      "accuracy:  0.7309728242747583\n",
      "Epoch 25/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.8078 - val_loss: 6.8024\n",
      "accuracy:  0.7363871290430143\n",
      "Epoch 26/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 75s 78us/step - loss: 6.8016 - val_loss: 6.8078\n",
      "accuracy:  0.7360661887295765\n",
      "Epoch 27/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 75s 78us/step - loss: 6.7951 - val_loss: 6.7974\n",
      "accuracy:  0.7362620873624541\n",
      "Epoch 28/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.7882 - val_loss: 6.7977\n",
      "accuracy:  0.7351908969656552\n",
      "Epoch 29/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 77us/step - loss: 6.7816 - val_loss: 6.7866\n",
      "accuracy:  0.739450650216739\n",
      "Epoch 30/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 77s 80us/step - loss: 6.7747 - val_loss: 6.7791\n",
      "accuracy:  0.7454109703234412\n",
      "Epoch 31/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.7695 - val_loss: 6.7635\n",
      "accuracy:  0.7471198732910971\n",
      "Epoch 32/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.7623 - val_loss: 6.7600\n",
      "accuracy:  0.748024341447149\n",
      "Epoch 33/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 82s 85us/step - loss: 6.7565 - val_loss: 6.7481\n",
      "accuracy:  0.7510128376125376\n",
      "Epoch 34/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 93us/step - loss: 6.7513 - val_loss: 6.7540\n",
      "accuracy:  0.750700233411137\n",
      "Epoch 35/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 93us/step - loss: 6.7459 - val_loss: 6.7313\n",
      "accuracy:  0.753592864288096\n",
      "Epoch 36/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 88s 91us/step - loss: 6.7404 - val_loss: 6.7387\n",
      "accuracy:  0.7521132044014671\n",
      "Epoch 37/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 85us/step - loss: 6.7357 - val_loss: 6.7303\n",
      "accuracy:  0.7557685895298433\n",
      "Epoch 38/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 82s 85us/step - loss: 6.7310 - val_loss: 6.7323\n",
      "accuracy:  0.7511045348449483\n",
      "Epoch 39/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 88us/step - loss: 6.7262 - val_loss: 6.7252\n",
      "accuracy:  0.7523132710903635\n",
      "Epoch 40/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 88s 92us/step - loss: 6.7202 - val_loss: 6.7169\n",
      "accuracy:  0.7594948316105369\n",
      "Epoch 41/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959680/959680 [==============================] - 85s 89us/step - loss: 6.7151 - val_loss: 6.7235\n",
      "accuracy:  0.7571607202400801\n",
      "Epoch 42/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.7091 - val_loss: 6.7082\n",
      "accuracy:  0.7607077359119706\n",
      "Epoch 43/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 88us/step - loss: 6.7015 - val_loss: 6.7047\n",
      "accuracy:  0.7640713571190397\n",
      "Epoch 44/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 89us/step - loss: 6.6957 - val_loss: 6.7040\n",
      "accuracy:  0.7630293431143714\n",
      "Epoch 45/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 88s 91us/step - loss: 6.6901 - val_loss: 6.7026\n",
      "accuracy:  0.7614954984994998\n",
      "Epoch 46/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 88s 92us/step - loss: 6.6843 - val_loss: 6.6873\n",
      "accuracy:  0.7666722240746916\n",
      "Epoch 47/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 87s 90us/step - loss: 6.6795 - val_loss: 6.6825\n",
      "accuracy:  0.7711070356785595\n",
      "Epoch 48/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 87s 90us/step - loss: 6.6761 - val_loss: 6.6693\n",
      "accuracy:  0.7718447815938646\n",
      "Epoch 49/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 84s 87us/step - loss: 6.6710 - val_loss: 6.6871\n",
      "accuracy:  0.7695023341113705\n",
      "Epoch 50/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.6661 - val_loss: 6.6694\n",
      "accuracy:  0.7751375458486162\n",
      "Epoch 51/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 78us/step - loss: 6.6627 - val_loss: 6.6638\n",
      "accuracy:  0.7757877625875291\n",
      "Epoch 52/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 83us/step - loss: 6.6591 - val_loss: 6.6501\n",
      "accuracy:  0.7713112704234745\n",
      "Epoch 53/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 75s 78us/step - loss: 6.6563 - val_loss: 6.6605\n",
      "accuracy:  0.7786303767922641\n",
      "Epoch 54/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.6530 - val_loss: 6.6685\n",
      "accuracy:  0.7724116372124041\n",
      "Epoch 55/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6504 - val_loss: 6.6561\n",
      "accuracy:  0.7784969989996665\n",
      "Epoch 56/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 75s 79us/step - loss: 6.6482 - val_loss: 6.6475\n",
      "accuracy:  0.7763712904301434\n",
      "Epoch 57/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 83us/step - loss: 6.6445 - val_loss: 6.6437\n",
      "accuracy:  0.7805976992330776\n",
      "Epoch 58/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.6410 - val_loss: 6.6407\n",
      "accuracy:  0.7816563854618206\n",
      "Epoch 59/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.6391 - val_loss: 6.6392\n",
      "accuracy:  0.7824524841613871\n",
      "Epoch 60/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.6365 - val_loss: 6.6394\n",
      "accuracy:  0.7792347449149717\n",
      "Epoch 61/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.6344 - val_loss: 6.6336\n",
      "accuracy:  0.7815438479493164\n",
      "Epoch 62/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 82us/step - loss: 6.6323 - val_loss: 6.6279\n",
      "accuracy:  0.7851283761253751\n",
      "Epoch 63/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6302 - val_loss: 6.6336\n",
      "accuracy:  0.7760753584528176\n",
      "Epoch 64/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.6290 - val_loss: 6.6352\n",
      "accuracy:  0.777000666888963\n",
      "Epoch 65/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.6268 - val_loss: 6.6204\n",
      "accuracy:  0.7836903967989329\n",
      "Epoch 66/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.6254 - val_loss: 6.6280\n",
      "accuracy:  0.7828609536512171\n",
      "Epoch 67/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.6234 - val_loss: 6.6156\n",
      "accuracy:  0.7880918639546516\n",
      "Epoch 68/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6211 - val_loss: 6.6176\n",
      "accuracy:  0.788187729243081\n",
      "Epoch 69/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.6179 - val_loss: 6.6129\n",
      "accuracy:  0.7871540513504501\n",
      "Epoch 70/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 75s 78us/step - loss: 6.6157 - val_loss: 6.6081\n",
      "accuracy:  0.7876708902967656\n",
      "Epoch 71/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6133 - val_loss: 6.6138\n",
      "accuracy:  0.7849033011003668\n",
      "Epoch 72/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.6110 - val_loss: 6.6027\n",
      "accuracy:  0.7932269089696565\n",
      "Epoch 73/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6087 - val_loss: 6.6101\n",
      "accuracy:  0.7916555518506169\n",
      "Epoch 74/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 77s 80us/step - loss: 6.6068 - val_loss: 6.6077\n",
      "accuracy:  0.7894964988329443\n",
      "Epoch 75/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 77us/step - loss: 6.6051 - val_loss: 6.6124\n",
      "accuracy:  0.7864454818272758\n",
      "Epoch 76/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.6036 - val_loss: 6.6026\n",
      "accuracy:  0.7910886962320773\n",
      "Epoch 77/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 77us/step - loss: 6.6015 - val_loss: 6.5992\n",
      "accuracy:  0.7911053684561521\n",
      "Epoch 78/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 80us/step - loss: 6.6006 - val_loss: 6.6062\n",
      "accuracy:  0.790621873957986\n",
      "Epoch 79/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 82us/step - loss: 6.5988 - val_loss: 6.6078\n",
      "accuracy:  0.7938604534844949\n",
      "Epoch 80/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 73s 76us/step - loss: 6.5978 - val_loss: 6.5929\n",
      "accuracy:  0.7959153051017006\n",
      "Epoch 81/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 77us/step - loss: 6.5963 - val_loss: 6.5977\n",
      "accuracy:  0.7911928976325442\n",
      "Epoch 82/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.5949 - val_loss: 6.5986\n",
      "accuracy:  0.7910470156718906\n",
      "Epoch 83/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 92us/step - loss: 6.5934 - val_loss: 6.5991\n",
      "accuracy:  0.7949441480493498\n",
      "Epoch 84/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 92us/step - loss: 6.5928 - val_loss: 6.5875\n",
      "accuracy:  0.799274758252751\n",
      "Epoch 85/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 93us/step - loss: 6.5902 - val_loss: 6.5997\n",
      "accuracy:  0.7970990330110037\n",
      "Epoch 86/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 87s 91us/step - loss: 6.5875 - val_loss: 6.5777\n",
      "accuracy:  0.7952359119706569\n",
      "Epoch 87/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 89us/step - loss: 6.5862 - val_loss: 6.5934\n",
      "accuracy:  0.795973657885962\n",
      "Epoch 88/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.5846 - val_loss: 6.5945\n",
      "accuracy:  0.7914263087695899\n",
      "Epoch 89/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.5837 - val_loss: 6.5888\n",
      "accuracy:  0.7981577192397465\n",
      "Epoch 90/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 84us/step - loss: 6.5825 - val_loss: 6.5797\n",
      "accuracy:  0.7957194064688229\n",
      "Epoch 91/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.5816 - val_loss: 6.5777\n",
      "accuracy:  0.79689063021007\n",
      "Epoch 92/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.5802 - val_loss: 6.5813\n",
      "accuracy:  0.7940521840613538\n",
      "Epoch 93/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 82s 86us/step - loss: 6.5794 - val_loss: 6.5773\n",
      "accuracy:  0.7992414138046016\n",
      "Epoch 94/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 81s 84us/step - loss: 6.5788 - val_loss: 6.5759\n",
      "accuracy:  0.7980035011670557\n",
      "Epoch 95/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.5772 - val_loss: 6.5699\n",
      "accuracy:  0.7981327109036346\n",
      "Epoch 96/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.5765 - val_loss: 6.5796\n",
      "accuracy:  0.8006293764588196\n",
      "Epoch 97/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.5754 - val_loss: 6.5915\n",
      "accuracy:  0.798203567855952\n",
      "Epoch 98/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 82us/step - loss: 6.5745 - val_loss: 6.5782\n",
      "accuracy:  0.8003959653217739\n",
      "Epoch 99/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 76s 79us/step - loss: 6.5734 - val_loss: 6.5944\n",
      "accuracy:  0.7988371123707902\n",
      "Epoch 100/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 84us/step - loss: 6.5714 - val_loss: 6.5721\n",
      "accuracy:  0.7970031677225742\n",
      "Epoch 101/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.5700 - val_loss: 6.5704\n",
      "accuracy:  0.7998124374791598\n",
      "Epoch 102/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.5683 - val_loss: 6.5763\n",
      "accuracy:  0.800420973657886\n",
      "Epoch 103/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 77s 81us/step - loss: 6.5670 - val_loss: 6.5707\n",
      "accuracy:  0.8002000666888963\n",
      "Epoch 104/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 78s 81us/step - loss: 6.5661 - val_loss: 6.5752\n",
      "accuracy:  0.8021048682894298\n",
      "Epoch 105/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 74s 77us/step - loss: 6.5653 - val_loss: 6.5667\n",
      "accuracy:  0.8027509169723241\n",
      "Epoch 106/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 83us/step - loss: 6.5645 - val_loss: 6.5574\n",
      "accuracy:  0.8062604201400467\n",
      "Epoch 107/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 87s 91us/step - loss: 6.5637 - val_loss: 6.5730\n",
      "accuracy:  0.8000625208402801\n",
      "Epoch 108/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 2872s 3ms/step - loss: 6.5628 - val_loss: 6.5558\n",
      "accuracy:  0.8044223074358119\n",
      "Epoch 109/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 58s 61us/step - loss: 6.5616 - val_loss: 6.5577\n",
      "accuracy:  0.8071398799599867\n",
      "Epoch 110/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 82us/step - loss: 6.5614 - val_loss: 6.5633\n",
      "accuracy:  0.8034803267755919\n",
      "Epoch 111/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 80s 83us/step - loss: 6.5602 - val_loss: 6.5583\n",
      "accuracy:  0.8048016005335111\n",
      "Epoch 112/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 79s 83us/step - loss: 6.5594 - val_loss: 6.5575\n",
      "accuracy:  0.8047057352450817\n",
      "Epoch 113/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 88s 92us/step - loss: 6.5585 - val_loss: 6.5654\n",
      "accuracy:  0.8045723574524841\n",
      "Epoch 114/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 88us/step - loss: 6.5578 - val_loss: 6.5615\n",
      "accuracy:  0.8036970656885628\n",
      "Epoch 115/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 89s 93us/step - loss: 6.5576 - val_loss: 6.5573\n",
      "accuracy:  0.8055768589529844\n",
      "Epoch 116/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 87s 91us/step - loss: 6.5561 - val_loss: 6.5488\n",
      "accuracy:  0.8059978326108703\n",
      "Epoch 117/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 49s 51us/step - loss: 6.5559 - val_loss: 6.5548\n",
      "accuracy:  0.8075150050016672\n",
      "Epoch 118/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5550 - val_loss: 6.5525\n",
      "accuracy:  0.8062770923641214\n",
      "Epoch 119/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 48s 50us/step - loss: 6.5542 - val_loss: 6.5593\n",
      "accuracy:  0.8086695565188396\n",
      "Epoch 120/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.5536 - val_loss: 6.5705\n",
      "accuracy:  0.8025675225075025\n",
      "Epoch 121/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.5534 - val_loss: 6.5534\n",
      "accuracy:  0.8055893631210403\n",
      "Epoch 122/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.5523 - val_loss: 6.5541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8078942980993664\n",
      "Epoch 123/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 46s 48us/step - loss: 6.5522 - val_loss: 6.5512\n",
      "accuracy:  0.8081027009003001\n",
      "Epoch 124/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5517 - val_loss: 6.5569\n",
      "accuracy:  0.8088237745915305\n",
      "Epoch 125/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 42s 44us/step - loss: 6.5511 - val_loss: 6.5548\n",
      "accuracy:  0.80351783927976\n",
      "Epoch 126/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5512 - val_loss: 6.5558\n",
      "accuracy:  0.8049683227742581\n",
      "Epoch 127/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5501 - val_loss: 6.5648\n",
      "accuracy:  0.8045015005001668\n",
      "Epoch 128/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5497 - val_loss: 6.5489\n",
      "accuracy:  0.8052600866955651\n",
      "Epoch 129/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5488 - val_loss: 6.5478\n",
      "accuracy:  0.8074441480493498\n",
      "Epoch 130/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5487 - val_loss: 6.5506\n",
      "accuracy:  0.8089404801600534\n",
      "Epoch 131/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5480 - val_loss: 6.5519\n",
      "accuracy:  0.8060770256752251\n",
      "Epoch 132/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5476 - val_loss: 6.5586\n",
      "accuracy:  0.8063312770923641\n",
      "Epoch 133/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 44s 46us/step - loss: 6.5471 - val_loss: 6.5423\n",
      "accuracy:  0.8104284761587196\n",
      "Epoch 134/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 45s 47us/step - loss: 6.5465 - val_loss: 6.5470\n",
      "accuracy:  0.809607369123041\n",
      "Epoch 135/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5460 - val_loss: 6.5668\n",
      "accuracy:  0.8084903301100367\n",
      "Epoch 136/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 43s 45us/step - loss: 6.5460 - val_loss: 6.5513\n",
      "accuracy:  0.8074483161053685\n",
      "Epoch 137/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 49s 52us/step - loss: 6.5450 - val_loss: 6.5374\n",
      "accuracy:  0.806410470156719\n",
      "Epoch 138/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 85s 89us/step - loss: 6.5447 - val_loss: 6.5605\n",
      "accuracy:  0.8045848616205402\n",
      "Epoch 139/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5441 - val_loss: 6.5450\n",
      "accuracy:  0.8095615205068356\n",
      "Epoch 140/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5433 - val_loss: 6.5498\n",
      "accuracy:  0.8100866955651884\n",
      "Epoch 141/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.5425 - val_loss: 6.5460\n",
      "accuracy:  0.8111037012337445\n",
      "Epoch 142/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.5427 - val_loss: 6.5369\n",
      "accuracy:  0.8109161387129044\n",
      "Epoch 143/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5417 - val_loss: 6.5494\n",
      "accuracy:  0.8105910303434478\n",
      "Epoch 144/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5412 - val_loss: 6.5496\n",
      "accuracy:  0.8114079693231077\n",
      "Epoch 145/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5405 - val_loss: 6.5397\n",
      "accuracy:  0.8102909303101034\n",
      "Epoch 146/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.5407 - val_loss: 6.5427\n",
      "accuracy:  0.8123999666555518\n",
      "Epoch 147/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5407 - val_loss: 6.5388\n",
      "accuracy:  0.8109786595531844\n",
      "Epoch 148/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 41s 42us/step - loss: 6.5393 - val_loss: 6.5248\n",
      "accuracy:  0.8153842947649217\n",
      "Epoch 149/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5390 - val_loss: 6.5410\n",
      "accuracy:  0.8089779926642214\n",
      "Epoch 150/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5387 - val_loss: 6.5400\n",
      "accuracy:  0.8104326442147383\n",
      "Epoch 151/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 40s 41us/step - loss: 6.5384 - val_loss: 6.5326\n",
      "accuracy:  0.8118872957652551\n",
      "Epoch 152/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 40us/step - loss: 6.5381 - val_loss: 6.5482\n",
      "accuracy:  0.8108661220406802\n",
      "Epoch 153/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5373 - val_loss: 6.5381\n",
      "accuracy:  0.8129168056018673\n",
      "Epoch 154/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5370 - val_loss: 6.5318\n",
      "accuracy:  0.8127584194731577\n",
      "Epoch 155/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5368 - val_loss: 6.5405\n",
      "accuracy:  0.8132044014671557\n",
      "Epoch 156/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5361 - val_loss: 6.5297\n",
      "accuracy:  0.8121165388462821\n",
      "Epoch 157/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5363 - val_loss: 6.5339\n",
      "accuracy:  0.8116288762920973\n",
      "Epoch 158/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5360 - val_loss: 6.5358\n",
      "accuracy:  0.810653551183728\n",
      "Epoch 159/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5358 - val_loss: 6.5436\n",
      "accuracy:  0.8124749916638879\n",
      "Epoch 160/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5353 - val_loss: 6.5405\n",
      "accuracy:  0.8117205735245082\n",
      "Epoch 161/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5347 - val_loss: 6.5361\n",
      "accuracy:  0.812449983327776\n",
      "Epoch 162/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5348 - val_loss: 6.5523\n",
      "accuracy:  0.8079609869956652\n",
      "Epoch 163/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5342 - val_loss: 6.5421\n",
      "accuracy:  0.812079026342114\n",
      "Epoch 164/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5344 - val_loss: 6.5286\n",
      "accuracy:  0.8163929643214405\n",
      "Epoch 165/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5343 - val_loss: 6.5307\n",
      "accuracy:  0.8113329443147715\n",
      "Epoch 166/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5339 - val_loss: 6.5329\n",
      "accuracy:  0.8159511503834611\n",
      "Epoch 167/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5334 - val_loss: 6.5493\n",
      "accuracy:  0.8100575191730577\n",
      "Epoch 168/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5332 - val_loss: 6.5395\n",
      "accuracy:  0.8094531510503501\n",
      "Epoch 169/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5331 - val_loss: 6.5370\n",
      "accuracy:  0.8154384794931644\n",
      "Epoch 170/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5330 - val_loss: 6.5370\n",
      "accuracy:  0.8169473157719239\n",
      "Epoch 171/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5323 - val_loss: 6.5310\n",
      "accuracy:  0.8127542514171391\n",
      "Epoch 172/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5327 - val_loss: 6.5251\n",
      "accuracy:  0.8156093697899299\n",
      "Epoch 173/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5319 - val_loss: 6.5369\n",
      "accuracy:  0.8148216072024008\n",
      "Epoch 174/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5315 - val_loss: 6.5299\n",
      "accuracy:  0.8145048349449817\n",
      "Epoch 175/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5314 - val_loss: 6.5360\n",
      "accuracy:  0.8088071023674558\n",
      "Epoch 176/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5310 - val_loss: 6.5331\n",
      "accuracy:  0.8141797265755252\n",
      "Epoch 177/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 39s 41us/step - loss: 6.5307 - val_loss: 6.5203\n",
      "accuracy:  0.8142922640880293\n",
      "Epoch 178/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5298 - val_loss: 6.5249\n",
      "accuracy:  0.8168347782594199\n",
      "Epoch 179/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5302 - val_loss: 6.5371\n",
      "accuracy:  0.8131793931310437\n",
      "Epoch 180/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5294 - val_loss: 6.5232\n",
      "accuracy:  0.8141588862954318\n",
      "Epoch 181/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 41s 43us/step - loss: 6.5293 - val_loss: 6.5307\n",
      "accuracy:  0.8148382794264755\n",
      "Epoch 182/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5293 - val_loss: 6.5350\n",
      "accuracy:  0.8150050016672225\n",
      "Epoch 183/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5292 - val_loss: 6.5282\n",
      "accuracy:  0.814959153051017\n",
      "Epoch 184/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5287 - val_loss: 6.5281\n",
      "accuracy:  0.8109411470490163\n",
      "Epoch 185/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5285 - val_loss: 6.5282\n",
      "accuracy:  0.819852450816939\n",
      "Epoch 186/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5287 - val_loss: 6.5293\n",
      "accuracy:  0.8115663554518173\n",
      "Epoch 187/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5276 - val_loss: 6.5404\n",
      "accuracy:  0.8112704234744915\n",
      "Epoch 188/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5279 - val_loss: 6.5315\n",
      "accuracy:  0.816743081027009\n",
      "Epoch 189/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5278 - val_loss: 6.5174\n",
      "accuracy:  0.8167222407469157\n",
      "Epoch 190/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5274 - val_loss: 6.5301\n",
      "accuracy:  0.8137254084694898\n",
      "Epoch 191/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5269 - val_loss: 6.5300\n",
      "accuracy:  0.8148757919306435\n",
      "Epoch 192/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5269 - val_loss: 6.5194\n",
      "accuracy:  0.8151508836278759\n",
      "Epoch 193/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5265 - val_loss: 6.5340\n",
      "accuracy:  0.8159011337112371\n",
      "Epoch 194/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5258 - val_loss: 6.5416\n",
      "accuracy:  0.8109911637212404\n",
      "Epoch 195/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5257 - val_loss: 6.5291\n",
      "accuracy:  0.8122082360786929\n",
      "Epoch 196/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5257 - val_loss: 6.5228\n",
      "accuracy:  0.8163637879293097\n",
      "Epoch 197/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5248 - val_loss: 6.5193\n",
      "accuracy:  0.8210070023341114\n",
      "Epoch 198/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 37s 39us/step - loss: 6.5256 - val_loss: 6.5289\n",
      "accuracy:  0.8125958652884295\n",
      "Epoch 199/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 40us/step - loss: 6.5242 - val_loss: 6.5260\n",
      "accuracy:  0.8156010336778926\n",
      "Epoch 200/200\n",
      "Train on 959680 samples, validate on 239920 samples\n",
      "Epoch 1/1\n",
      "959680/959680 [==============================] - 38s 39us/step - loss: 6.5247 - val_loss: 6.5176\n",
      "accuracy:  0.8161178726242081\n"
     ]
    }
   ],
   "source": [
    "# 固定神經元個數，比較訓練不同 epoch 次數之影響\n",
    "epoch_size = 200\n",
    "\n",
    "input1 = Input(shape=(91,))\n",
    "w1 = Dense(300, activation='relu', name='weight1')\n",
    "dense1 = w1(input1)\n",
    "w2 = Dense(52, activation='softmax', name='weight2')\n",
    "output1 = w2(dense1)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output1])\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy'])\n",
    "\n",
    "accuracy_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for i in range(1, epoch_size+1):\n",
    "    print('Epoch {}/{}'.format(i, epoch_size))\n",
    "    h = model.fit(x=[ctrain_x], y=[ctrain_y], validation_data=[cvalid_x, cvalid_y])\n",
    "    train_loss_list.append(h.history['loss'][0])\n",
    "    val_loss_list.append(h.history['val_loss'][0])\n",
    "    \n",
    "    # 預測測試集\n",
    "    predicted = model.predict(cvalid_x).reshape(cvalid_x.shape[0], 4, 13)\n",
    "    # 將預測結果(one-hot編碼)轉回一般數值\n",
    "    labels = []\n",
    "    ans = []\n",
    "    for i in range(0, len(valid_y)):\n",
    "      labels.append(ctable.decode(valid_y[i]))\n",
    "      ans.append(ctable.decode(predicted[i]))\n",
    "\n",
    "    # 計算正確率\n",
    "    acc = accuracy_score(ans, labels)\n",
    "    print('accuracy: ', acc)\n",
    "    accuracy_list.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下方兩張圖:\n",
    "## 第一張是隨著training epoch變多，訓練誤差和驗證誤差均持續降低。\n",
    "## 第二張圖則是隨著training epoch變多，驗證accuracy持續上升至收斂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 隨著 epoch 次數不同，loss 之變化\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(1, epoch_size+1, 1), train_loss_list, label='train_loss')\n",
    "plt.plot(range(1, epoch_size+1, 1), val_loss_list, label='valid_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 隨著 epoch 次數不同，accuracy 之變化\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(accuracy_list, label='valid_accuracy' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用測試集評估最終結果，accuracy 0.8171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8171723907969323\n"
     ]
    }
   ],
   "source": [
    "# 預測測試集\n",
    "predicted = model.predict(ctest_x).reshape(ctest_x.shape[0], 4, 13)\n",
    "# 將預測結果(one-hot編碼)轉回一般數值\n",
    "labels = []\n",
    "ans = []\n",
    "for i in range(0, len(ctest_y)):\n",
    "  labels.append(ctable.decode(test_y[i]))\n",
    "  ans.append(ctable.decode(predicted[i]))\n",
    "\n",
    "# 計算正確率\n",
    "acc = accuracy_score(ans, labels)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x: 856+694\n",
      "test_y: 1550\n",
      "predicted: 1550\n"
     ]
    }
   ],
   "source": [
    "# i = 4\n",
    "# print('test_x:', ctable.decode(test_x[i]))\n",
    "# print('test_y:',  ctable.decode(test_y[i]))\n",
    "# print('predicted:', ctable.decode(predicted[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
